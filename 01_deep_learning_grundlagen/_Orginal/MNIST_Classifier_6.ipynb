{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "PXtCqPUeHUGd",
        "Z9La9BjQ4ML5",
        "gCKE8ot8GJmL",
        "OqjUlkXTG34a"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST Klassifikation\n",
        "In diesem Notebook erstellen wir ein einfaches Neuronales Netzwerk mithilfe von pytorch um den MNIST Datensatz zu Klassifizieren. Dabei gehen wir entsprechend der [good practice des Deep Learning nach Kaparthy](https://karpathy.github.io/2019/04/25/recipe/) vor.\n",
        "\n",
        "1. Data Exploration\n",
        "2. Model & Traininsloop erstellen\n",
        "3. Evaluieren\n",
        "4. Overfitten\n",
        "5. Regularisieren\n",
        "6. Optimieren"
      ],
      "metadata": {
        "id": "_Xl6CxGgx2Ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data Exploration\n",
        "\n",
        "Als erstes werden wir die Daten erkunden, um wertvolle Erkenntnisse aus den vorliegenden Daten zu gewinnen. Dabei werden wir verschiedene Analysetechniken und Visualisierungsmethoden einsetzen, um ein umfassendes Verständnis des Datensatzes zu entwickeln. Ziel ist es, Muster, Trends und Zusammenhänge innerhalb der Daten zu identifizieren und darauf aufbauend fundierte Entscheidungen treffen zu können, zB welche Informationen den Daten entnommen werden können und welches Modell sich dazu eignet."
      ],
      "metadata": {
        "id": "PXtCqPUeHUGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zunächst laden wir die standardmässig verwendeten Module und den Datensatz."
      ],
      "metadata": {
        "id": "6QxIUqCsHc-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# Lade den MNIST-Datensatz\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)"
      ],
      "metadata": {
        "id": "KIYtpMqaHQ_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die Inputdaten befinden sich nun in\n",
        "\n",
        "\n",
        "```\n",
        "mnist.data\n",
        "```\n",
        " Die Klassenlabel in\n",
        "\n",
        " ```\n",
        " mnist.target\n",
        " ```\n"
      ],
      "metadata": {
        "id": "GevFgv-_JfTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aufgabe 1.1\n",
        "### Welches Format haben die Daten?\n",
        "Wir betrachten das Format der Daten. Bestimmen Sie dazu\n",
        "1. die Grösse des Datensatzes: N_data\n",
        "2. die Dimension der einzelnen Input-Daten: size_input\n",
        "3. den Container des Input Daten: container_input\n",
        "4. den Input datentyp: dtype_input\n",
        "5. den Datentyp der Label: dtype_output\n",
        "6. den Wertebereich der Input-Daten: mini, maxi\n",
        "7. die möglichen Outputwerte: labels_list"
      ],
      "metadata": {
        "id": "V6_CQUbLI31-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "##############################################\n",
        "############ ENTER YOUR CODE HERE ############\n",
        "##############################################\n",
        "\n",
        "# Grösse des Datensatzes\n",
        "N_data, size_input = mnist.data.shape\n",
        "# Input container\n",
        "container_input = type(mnist.data[0])\n",
        "# Datentypen\n",
        "dtype_input = mnist.data.dtype\n",
        "dtype_output = type(mnist.target[0])\n",
        "# Wertebereich\n",
        "mini, maxi = mnist.data.min(), mnist.data.max()\n",
        "labels_list = np.unique(mnist.target)\n",
        "\n",
        "##############################################\n",
        "##############################################\n",
        "##############################################\n",
        "\n",
        "\n",
        "\n",
        "print(\"Format des Datensatzes:\")\n",
        "print(\"Anzahl Datenpunkte:\", N_data)\n",
        "print(\"Dimension der Input Daten:\", size_input)\n",
        "print(\"Input Container:\", container_input)\n",
        "print(\"Input Datentyp:\", dtype_input)\n",
        "print(\"Output Datentyp:\", dtype_output)\n",
        "print(\"Input Wertebereich:\", f\"[{mini},{maxi}]\")\n",
        "print(\"Output Werte:\", f\"{labels_list}\")"
      ],
      "metadata": {
        "id": "x7NsBd3nI4NF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f6b1884-3638-4b3f-e889-b4b970d962a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Format des Datensatzes:\n",
            "Anzahl Datenpunkte: 70000\n",
            "Dimension der Input Daten: 784\n",
            "Input Container: <class 'numpy.ndarray'>\n",
            "Input Datentyp: int64\n",
            "Output Datentyp: <class 'str'>\n",
            "Input Wertebereich: [0,255]\n",
            "Output Werte: ['0' '1' '2' '3' '4' '5' '6' '7' '8' '9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Welche Daten enthält der Datensatz?\n",
        "\n",
        "Nun betrachten wir ein paar Datenbeispiele. Bei den Daten handelt es sich um Bilder mit einem string label. Wir plotten ein paar dieser Bilder zusammen mit deren Label."
      ],
      "metadata": {
        "id": "mHXsJsfnB8d8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPDKlwptG1lK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82ec7bd0-3783-4df1-c1c8-b7e4d9ba7f97"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 25 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot 25 example images with labels as titles\n",
        "fig, axs = plt.subplots(5, 5, figsize=(10, 10))\n",
        "for i, ax in enumerate(axs.flatten()):\n",
        "    ax.imshow(mnist.data[i].reshape(28, 28), cmap='gray')\n",
        "    ax.set_title(f\"label = {mnist.target[i]}\")\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bei den Daten handelt es sich um Schwarz-Weiss Bilder von handgeschriebenen Ziffern. Das Label gibt an, welche Ziffer im Bild geschrieben steht."
      ],
      "metadata": {
        "id": "txrLk-qUIODF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aufgabe 1.2\n",
        "### Welche Klassen gibt es und wie sind diese Verteilt?\n",
        "Nun betrachten wir die Verteilung der Klassen. Berechnen und plotten Sie dazu das Histogram der Label."
      ],
      "metadata": {
        "id": "yYjVODKaIdBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "##############################################\n",
        "############ ENTER YOUR CODE HERE ############\n",
        "##############################################\n",
        "\n",
        "# NumPy Histogramm-Berechnung\n",
        "counts = np.bincount(mnist.target.astype(int))\n",
        "\n",
        "##############################################\n",
        "##############################################\n",
        "##############################################\n",
        "\n",
        "\n",
        "# Histogramm-Plot\n",
        "plt.bar(labels_list, counts, edgecolor='black')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Anzahl')\n",
        "plt.title('Histogramm der Datenverteilung')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Nop7DLAUG3X4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4666a26a-6a31-4ef4-d888-3f193205a039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHHCAYAAABeLEexAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAASy1JREFUeJzt3XlcVHX///8noCwugEuAJCIuKbgmppKVG0leaHlppWWKS5dmqCFdWl6Vu6HmWm6ZXlKpuVyfS3PJBfdU3CjKNE3TwjTgMgVcQeH8/ujH+TriAqYMeh732+3cct7v15x5ncN0m+ecOWfGwTAMQwAAABbmaO8GAAAA7I1ABAAALI9ABAAALI9ABAAALI9ABAAALI9ABAAALI9ABAAALI9ABAAALI9ABAAALI9ABNxE5cqV1b17d3u3gWs0b95czZs3t3cbuIeu/xv/8ssvcnBwUGxsrN16gjUQiGAJsbGxcnBw0L59+24437x5c9WuXfsvP85XX32l4cOH/+X1wP6aN28uBwcHOTg4yNHRUe7u7qpRo4a6du2quLi4v7TuGTNmPJAv8Dz/cT8rZu8GgKLq8OHDcnQs2HuGr776StOnT+dF4QFRsWJFxcTESJIuXLigo0eP6r///a/mz5+vF198UfPnz1fx4sULvN4ZM2aofPnyD9wRyLvx/F+/fv3dawgoAAIRcBMuLi72bqHALly4oJIlS9q7jftCTk6OsrKy5OrqetMaDw8PvfLKKzZjY8eO1YABAzRjxgxVrlxZ48aNu9etFnl383nn7Ox8V9YDFBQfmQE3cf05RFeuXNGIESNUvXp1ubq6qly5cnriiSfMj0+6d++u6dOnS5L5UYuDg4N5/wsXLujNN9+Un5+fXFxcVKNGDU2YMEGGYdg87qVLlzRgwACVL19epUuX1rPPPquTJ0/KwcHB5p338OHD5eDgoIMHD+rll19WmTJl9MQTT0iSvv/+e3Xv3l1VqlSRq6urfHx81LNnT/3xxx82j5W7jp9++kmvvPKKPDw89NBDD+m9996TYRg6ceKEnnvuObm7u8vHx0cTJ060uf+WLVvk4OCgJUuWaMSIEXr44YdVunRpPf/880pPT1dmZqaioqLk5eWlUqVKqUePHsrMzMzX/p89e7aqVq0qNzc3NWrUSF9//fUN6zIzMzVs2DBVq1ZNLi4u8vPz0+DBg/M8joODg/r166cFCxaoVq1acnFx0dq1a/PVy7WcnJz04YcfKigoSNOmTVN6ero5N2/ePLVs2VJeXl5ycXFRUFCQZs6caXP/ypUr68CBA9q6dav5HLn2nJm0tDRFRUWZz5Nq1app3LhxysnJMWtyz6uZMGGCuZ9cXFz02GOPae/evWbdhAkT5ODgoF9//TXPdgwZMkTOzs46e/asObZ7924988wz8vDwUIkSJdSsWTPt2LHD5n43e97d7vmfk5OjKVOmqFatWnJ1dZW3t7f69Olj8/hS/s4Tu1lN9+7dVbly5QLvp1xLly5VUFCQXF1dVbt2bS1btizPOvHg4ggRLCU9PV2nT5/OM37lypXb3nf48OGKiYnRq6++qkaNGikjI0P79u3TN998o6efflp9+vTRqVOnFBcXp88//9zmvoZh6Nlnn9XmzZvVq1cv1a9fX+vWrdOgQYN08uRJTZ482azt3r27lixZoq5du6pJkybaunWrwsPDb9rXCy+8oOrVq+v99983w1VcXJyOHTumHj16yMfHRwcOHNDs2bN14MAB7dq1y+aFSpI6deqkwMBAjR07VqtXr9bo0aNVtmxZffzxx2rZsqXGjRunBQsW6J///Kcee+wxPfXUUzb3j4mJkZubm95++20dPXpUH330kYoXLy5HR0edPXtWw4cP165duxQbG6uAgAANHTr0lvt67ty56tOnjx5//HFFRUXp2LFjevbZZ1W2bFn5+fmZdTk5OXr22We1fft29e7dW4GBgdq/f78mT56sn376ScuXL7dZ76ZNm7RkyRL169dP5cuXv+MXOicnJ7300kt67733tH37dvPvM3PmTNWqVUvPPvusihUrppUrV+r1119XTk6OIiMjJUlTpkxR//79VapUKb3zzjuSJG9vb0nSxYsX1axZM508eVJ9+vRRpUqVtHPnTg0ZMkS///67pkyZYtPHwoULde7cOfXp00cODg4aP368OnTooGPHjql48eJ68cUXNXjwYC1ZskSDBg2yue+SJUvUunVrlSlTxtw3bdq0UXBwsIYNGyZHR0cz4H399ddq1KiRzf2vf949+uijN33+S1KfPn0UGxurHj16aMCAATp+/LimTZumb7/9Vjt27Lijjx7z63b7SZJWr16tTp06qU6dOoqJidHZs2fVq1cvPfzww/esLxQxBmAB8+bNMyTdcqlVq5bNffz9/Y2IiAjzdr169Yzw8PBbPk5kZKRxo/+tli9fbkgyRo8ebTP+/PPPGw4ODsbRo0cNwzCMhIQEQ5IRFRVlU9e9e3dDkjFs2DBzbNiwYYYk46WXXsrzeBcvXswz9sUXXxiSjG3btuVZR+/evc2xq1evGhUrVjQcHByMsWPHmuNnz5413NzcbPbJ5s2bDUlG7dq1jaysLHP8pZdeMhwcHIw2bdrY9BASEmL4+/vn6e1aWVlZhpeXl1G/fn0jMzPTHJ89e7YhyWjWrJk59vnnnxuOjo7G119/bbOOWbNmGZKMHTt2mGOSDEdHR+PAgQO3fPxczZo1y/OcuNayZcsMScbUqVPNsRvt97CwMKNKlSo2Y7Vq1bLZjlyjRo0ySpYsafz0008242+//bbh5ORkJCUlGYZhGMePHzckGeXKlTPOnDlj1n355ZeGJGPlypXmWEhIiBEcHGyzvj179hiSjM8++8wwDMPIyckxqlevboSFhRk5OTk22xMQEGA8/fTT5titnnc3e/5//fXXhiRjwYIFNuNr167NM96sWTObfZO7rfPmzbtpTa6IiAib51dB9lOdOnWMihUrGufOnTPHtmzZYki67XMWDwY+MoOlTJ8+XXFxcXmWunXr3va+np6eOnDggI4cOVLgx/3qq6/k5OSkAQMG2Iy/+eabMgxDa9askSTzI5zXX3/dpq5///43Xfdrr72WZ8zNzc389+XLl3X69Gk1adJEkvTNN9/kqX/11VfNfzs5Oalhw4YyDEO9evUyxz09PVWjRg0dO3Ysz/27detm8w6/cePGMgxDPXv2tKlr3LixTpw4oatXr950e/bt26fU1FS99tprNueTdO/eXR4eHja1S5cuVWBgoGrWrKnTp0+bS8uWLSVJmzdvtqlv1qyZgoKCbvrYBVGqVClJ0rlz58yxa/d77tHIZs2a6dixYzYfrd3M0qVL9eSTT6pMmTI22xMaGqrs7Gxt27bNpr5Tp07mER5JevLJJyXJ5m/UqVMnJSQk6OeffzbHFi9eLBcXFz333HOSpMTERB05ckQvv/yy/vjjD/NxL1y4oFatWmnbtm02H9lJN37e3Wq7PDw89PTTT9tsV3BwsEqVKpXn73S33W4/nTp1Svv371e3bt3Mv6v05/OlTp0697Q3FB18ZAZLadSokRo2bJhnPPcF6FZGjhyp5557To888ohq166tZ555Rl27ds1XmPr111/l6+ur0qVL24wHBgaa87n/dXR0VEBAgE1dtWrVbrru62sl6cyZMxoxYoQWLVqk1NRUm7kbvTBXqlTJ5raHh4dcXV1Vvnz5POPXn4d0s/tLsvl4K3c8JydH6enpKleu3A23J3dfVK9e3Wa8ePHiqlKlis3YkSNH9OOPP+qhhx664bqu3/Yb7as7df78eUmy+Zvu2LFDw4YNU3x8vC5evGhTn56enifQXe/IkSP6/vvv87091+/33Bf9a8/LeeGFFxQdHa3FixfrX//6lwzD0NKlS9WmTRu5u7ubjytJERERN+0tPT3dJlQUZF8eOXJE6enp8vLyytd23W2320+5z7kb/X9WrVq1G76JwIOHQATk01NPPaWff/5ZX375pdavX685c+Zo8uTJmjVrls0RlsJ27VGJXC+++KJ27typQYMGqX79+ipVqpRycnL0zDPP5HmnL/15VCg/Y5LynAR+q9qCrONO5OTkqE6dOpo0adIN568PZDfaV3fqhx9+kPT/XkR//vlntWrVSjVr1tSkSZPk5+cnZ2dnffXVV5o8efIN9/v1cnJy9PTTT2vw4ME3nH/kkUdsbudn//r6+urJJ5/UkiVL9K9//Uu7du1SUlKSzdVxub198MEHql+//g3Xee2RE6lg+zInJ0deXl5asGDBDedvFgBvxsHB4YbPoezs7BvW3+vnIR4MBCKgAMqWLasePXqoR48eOn/+vJ566ikNHz7cDETXn6ycy9/fXxs2bNC5c+dsjigcOnTInM/9b05Ojo4fP25zhOTo0aP57vHs2bPauHGjRowYYXPy8p181GcPufviyJEj5kdf0p8nvh8/flz16tUzx6pWrarvvvtOrVq1uum+vxeys7O1cOFClShRwryyb+XKlcrMzNSKFStsjkjc6OOgm/VatWpVnT9/XqGhoXe1306dOun111/X4cOHtXjxYpUoUULt2rWzeVxJcnd3/0uPfavt2rBhg5o2bXpXQmmZMmVu+NHtja6my4/c59yN/j8ryP97uL9xDhGQT9d/VFSqVClVq1bN5vLu3O9iSUtLs6n929/+puzsbE2bNs1mfPLkyXJwcFCbNm0kSWFhYZL+/OK+a3300Uf57jP33fD1736vv0KpqGrYsKEeeughzZo1S1lZWeZ4bGxsnv364osv6uTJk/rkk0/yrOfSpUu6cOHCXe8vOztbAwYM0I8//qgBAwaYHzvdaL+np6dr3rx5edZRsmTJPNsi/bk98fHxWrduXZ65tLS0W557dSsdO3aUk5OTvvjiCy1dulRt27a1+d6g4OBgVa1aVRMmTDA/CrzW//73v3w9zs2e/y+++KKys7M1atSoPPe5evXqDffFrVStWlWHDh2y6eu7777L8xUB+eXr66vatWvrs88+s9n+rVu3av/+/Xe0Ttx/OEIE5FNQUJCaN2+u4OBglS1bVvv27dN//vMf9evXz6wJDg6WJA0YMEBhYWFycnJS586d1a5dO7Vo0ULvvPOOfvnlF9WrV0/r16/Xl19+qaioKPMdenBwsDp27KgpU6bojz/+MC+7/+mnnyTd/B34tdzd3fXUU09p/PjxunLlih5++GGtX79ex48fvwd75e4rXry4Ro8erT59+qhly5bq1KmTjh8/rnnz5uU5h6hr165asmSJXnvtNW3evFlNmzZVdna2Dh06pCVLlmjdunU3PGcsv9LT0zV//nxJf14Sn/tN1T///LM6d+5s8wLfunVrOTs7q127durTp4/Onz+vTz75RF5eXvr9999t1hscHKyZM2dq9OjRqlatmry8vNSyZUsNGjRIK1asUNu2bdW9e3cFBwfrwoUL2r9/v/7zn//ol19+yXNeV354eXmpRYsWmjRpks6dO6dOnTrZzDs6OmrOnDlq06aNatWqpR49eujhhx/WyZMntXnzZrm7u2vlypW3fZybPf+bNWumPn36KCYmRomJiWrdurWKFy+uI0eOaOnSpZo6daqef/75fG9Pz549NWnSJIWFhalXr15KTU3VrFmzVKtWLWVkZBRs5/z/3n//fT333HNq2rSpevToobNnz2ratGmqXbv2DUMiHkB2uroNKFS5l93v3bv3hvM3usT6+svuR48ebTRq1Mjw9PQ03NzcjJo1axpjxoyxudz86tWrRv/+/Y2HHnrIcHBwsLkE+dy5c8bAgQMNX19fo3jx4kb16tWNDz74wOYyZ8MwjAsXLhiRkZFG2bJljVKlShnt27c3Dh8+bEiyuQw+9/Ln//3vf3m257fffjP+/ve/G56enoaHh4fxwgsvGKdOnbrppfvXryMiIsIoWbLkbfdT7mX3S5cutam72f6+Vc/XmzFjhhEQEGC4uLgYDRs2NLZt23bDy62zsrKMcePGGbVq1TJcXFyMMmXKGMHBwcaIESOM9PR0s06SERkZedvHvXZbdc3XMpQqVcqoXr268corrxjr16+/4X1WrFhh1K1b13B1dTUqV65sjBs3zvj3v/9tSDKOHz9u1iUnJxvh4eFG6dKl83yVwLlz54whQ4YY1apVM5ydnY3y5csbjz/+uDFhwgTzuZZ7OfkHH3yQp4fr/8a5PvnkE0OSUbp0aePSpUs37P/bb781OnToYJQrV85wcXEx/P39jRdffNHYuHGjWXOrv+Gtnv+G8edXJwQHBxtubm5G6dKljTp16hiDBw82Tp06ZbPfb3fZvWEYxvz5840qVaoYzs7ORv369Y1169bd9LL7/O6nRYsWGTVr1jRcXFyM2rVrGytWrDA6duxo1KxZ84b7Cw8WB8PgrDKgqEtMTNSjjz6q+fPnq0uXLvZuB7CM+vXr66GHHvrLP+iLoo9ziIAi5tKlS3nGpkyZIkdHxzzfEA3g7rhy5Uqec7S2bNmi77777rY/JYIHA+cQAUXM+PHjlZCQoBYtWqhYsWJas2aN1qxZo969e+e5jBzA3XHy5EmFhobqlVdeka+vrw4dOqRZs2bJx8enQF9CifsXH5kBRUxcXJxGjBihgwcP6vz586pUqZK6du2qd955R8WK8R4GuBfS09PVu3dv7dixQ//73/9UsmRJtWrVSmPHjjUvesCDjUAEAAAsj3OIAACA5RGIAACA5XFCQj7k5OTo1KlTKl26dKH+PAAAALhzhmHo3Llz8vX1laPjrY8BEYjy4dSpU1zdAwDAferEiROqWLHiLWsIRPmQ+2OcJ06cMH+3CAAAFG0ZGRny8/Oz+VHtmyEQ5UPux2Tu7u4EIgAA7jP5Od2Fk6oBAIDlEYgAAIDlEYgAAIDlEYgAAIDlEYgAAIDl2TUQZWdn67333lNAQIDc3NxUtWpVjRo1Stf+vJphGBo6dKgqVKggNzc3hYaG6siRIzbrOXPmjLp06SJ3d3d5enqqV69eOn/+vE3N999/ryeffFKurq7y8/PT+PHjC2UbAQBA0WfXQDRu3DjNnDlT06ZN048//qhx48Zp/Pjx+uijj8ya8ePH68MPP9SsWbO0e/dulSxZUmFhYbp8+bJZ06VLFx04cEBxcXFatWqVtm3bpt69e5vzGRkZat26tfz9/ZWQkKAPPvhAw4cP1+zZswt1ewEAQNFk11+7b9u2rby9vTV37lxzrGPHjnJzc9P8+fNlGIZ8fX315ptv6p///KckKT09Xd7e3oqNjVXnzp31448/KigoSHv37lXDhg0lSWvXrtXf/vY3/fbbb/L19dXMmTP1zjvvKDk5Wc7OzpKkt99+W8uXL9ehQ4du22dGRoY8PDyUnp7O9xABAHCfKMjrt12PED3++OPauHGjfvrpJ0nSd999p+3bt6tNmzaSpOPHjys5OVmhoaHmfTw8PNS4cWPFx8dLkuLj4+Xp6WmGIUkKDQ2Vo6Ojdu/ebdY89dRTZhiSpLCwMB0+fFhnz57N01dmZqYyMjJsFgAA8OCy6zdVv/3228rIyFDNmjXl5OSk7OxsjRkzRl26dJEkJScnS5K8vb1t7uft7W3OJScny8vLy2a+WLFiKlu2rE1NQEBAnnXkzpUpU8ZmLiYmRiNGjLhLWwkAAIo6ux4hWrJkiRYsWKCFCxfqm2++0aeffqoJEybo008/tWdbGjJkiNLT083lxIkTdu0HAADcW3Y9QjRo0CC9/fbb6ty5sySpTp06+vXXXxUTE6OIiAj5+PhIklJSUlShQgXzfikpKapfv74kycfHR6mpqTbrvXr1qs6cOWPe38fHRykpKTY1ubdza67l4uIiFxeXu7ORAACgyLPrEaKLFy/K0dG2BScnJ+Xk5EiSAgIC5OPjo40bN5rzGRkZ2r17t0JCQiRJISEhSktLU0JCglmzadMm5eTkqHHjxmbNtm3bdOXKFbMmLi5ONWrUyPNxGQAAsB67BqJ27dppzJgxWr16tX755RctW7ZMkyZN0t///ndJf/46bVRUlEaPHq0VK1Zo//796tatm3x9fdW+fXtJUmBgoJ555hn94x//0J49e7Rjxw7169dPnTt3lq+vryTp5ZdflrOzs3r16qUDBw5o8eLFmjp1qqKjo+216QAAoAix62X3586d03vvvadly5YpNTVVvr6+eumllzR06FDzijDDMDRs2DDNnj1baWlpeuKJJzRjxgw98sgj5nrOnDmjfv36aeXKlXJ0dFTHjh314YcfqlSpUmbN999/r8jISO3du1fly5dX//799dZbb+WrTy67v7GkpCSdPn3a3m3YKF++vCpVqmTvNgAARUBBXr/tGojuFwSivJKSklSjZqAuX7po71ZsuLqV0OFDPxKKAAAFev2260nVuH+dPn1aly9dVLm2b6p4OT97tyNJuvLHCf2xaqJOnz5NIAIAFAiBCH9J8XJ+cvGpZu82AAD4S/i1ewAAYHkEIgAAYHkEIgAAYHkEIgAAYHkEIgAAYHkEIgAAYHkEIgAAYHkEIgAAYHkEIgAAYHkEIgAAYHkEIgAAYHkEIgAAYHkEIgAAYHkEIgAAYHkEIgAAYHkEIgAAYHkEIgAAYHkEIgAAYHkEIgAAYHkEIgAAYHkEIgAAYHkEIgAAYHnF7N0AAABJSUk6ffq0vduwUb58eVWqVMnebaCQEIgAAHaVlJSkGjUDdfnSRXu3YsPVrYQOH/qRUGQRBCIAgF2dPn1aly9dVLm2b6p4OT97tyNJuvLHCf2xaqJOnz5NILIIAhEAoEgoXs5PLj7V7N0GLIqTqgEAgOURiAAAgOURiAAAgOVxDhFwn+CyZAC4dwhEwH2Ay5IB4N4iEAH3AS5LBoB7y66BqHLlyvr111/zjL/++uuaPn26Ll++rDfffFOLFi1SZmamwsLCNGPGDHl7e5u1SUlJ6tu3rzZv3qxSpUopIiJCMTExKlbs/23ali1bFB0drQMHDsjPz0/vvvuuunfvXhibCNxVXJYMAPeGXU+q3rt3r37//XdziYuLkyS98MILkqSBAwdq5cqVWrp0qbZu3apTp06pQ4cO5v2zs7MVHh6urKws7dy5U59++qliY2M1dOhQs+b48eMKDw9XixYtlJiYqKioKL366qtat25d4W4sAAAosux6hOihhx6yuT127FhVrVpVzZo1U3p6uubOnauFCxeqZcuWkqR58+YpMDBQu3btUpMmTbR+/XodPHhQGzZskLe3t+rXr69Ro0bprbfe0vDhw+Xs7KxZs2YpICBAEydOlCQFBgZq+/btmjx5ssLCwgp9mwEAQNFTZM4hysrK0vz58xUdHS0HBwclJCToypUrCg0NNWtq1qypSpUqKT4+Xk2aNFF8fLzq1Klj8xFaWFiY+vbtqwMHDujRRx9VfHy8zTpya6Kiom7aS2ZmpjIzM83bGRkZd29DYXdcrQUAuF6RCUTLly9XWlqaeW5PcnKynJ2d5enpaVPn7e2t5ORks+baMJQ7nzt3q5qMjAxdunRJbm5ueXqJiYnRiBEj7sZmoYjhai0AwI0UmUA0d+5ctWnTRr6+vvZuRUOGDFF0dLR5OyMjQ35+RePKHvw1XK0FABwpv5EiEYh+/fVXbdiwQf/973/NMR8fH2VlZSktLc3mKFFKSop8fHzMmj179tisKyUlxZzL/W/u2LU17u7uNzw6JEkuLi5ycXH5y9uFoourtQBYFUfKb6xIBKJ58+bJy8tL4eHh5lhwcLCKFy+ujRs3qmPHjpKkw4cPKykpSSEhIZKkkJAQjRkzRqmpqfLy8pIkxcXFyd3dXUFBQWbNV199ZfN4cXFx5jqKApI6AKCwcKT8xuweiHJycjRv3jxFRETYfHeQh4eHevXqpejoaJUtW1bu7u7q37+/QkJC1KRJE0lS69atFRQUpK5du2r8+PFKTk7Wu+++q8jISPMIz2uvvaZp06Zp8ODB6tmzpzZt2qQlS5Zo9erVdtne65HUAdxNvMFCfnGk3JbdA9GGDRuUlJSknj175pmbPHmyHB0d1bFjR5svZszl5OSkVatWqW/fvgoJCVHJkiUVERGhkSNHmjUBAQFavXq1Bg4cqKlTp6pixYqaM2dOkbnknqQO4G7hDRZw5+weiFq3bi3DMG445+rqqunTp2v69Ok3vb+/v3+ej8Su17x5c3377bd/qc97jaQO4K/iDRZw5+weiAA82PgIp/DxBqvw8Px+cBCIANwzfISDBxnP7wcLgQjAPcNHOHiQ8fx+sBCIANxzfISDBxnP7weDXX/tHgAAoCggEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsrZu8GAKAoSkpK0unTp+3dho3y5curUqVK9m4DeCARiADgOklJSapRM1CXL120dys2XN1K6PChHwlFwD1AIAKA65w+fVqXL11UubZvqng5P3u3I0m68scJ/bFqok6fPk0gAu4BAhEA3ETxcn5y8alm7zYAFAJOqgYAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZn90B08uRJvfLKKypXrpzc3NxUp04d7du3z5w3DENDhw5VhQoV5ObmptDQUB05csRmHWfOnFGXLl3k7u4uT09P9erVS+fPn7ep+f777/Xkk0/K1dVVfn5+Gj9+fKFsHwAAKPrsGojOnj2rpk2bqnjx4lqzZo0OHjyoiRMnqkyZMmbN+PHj9eGHH2rWrFnavXu3SpYsqbCwMF2+fNms6dKliw4cOKC4uDitWrVK27ZtU+/evc35jIwMtW7dWv7+/kpISNAHH3yg4cOHa/bs2YW6vQAAoGiy6xczjhs3Tn5+fpo3b545FhAQYP7bMAxNmTJF7777rp577jlJ0meffSZvb28tX75cnTt31o8//qi1a9dq7969atiwoSTpo48+0t/+9jdNmDBBvr6+WrBggbKysvTvf/9bzs7OqlWrlhITEzVp0iSb4AQAAKzJrkeIVqxYoYYNG+qFF16Ql5eXHn30UX3yySfm/PHjx5WcnKzQ0FBzzMPDQ40bN1Z8fLwkKT4+Xp6enmYYkqTQ0FA5Ojpq9+7dZs1TTz0lZ2dnsyYsLEyHDx/W2bNn7/VmAgCAIs6ugejYsWOaOXOmqlevrnXr1qlv374aMGCAPv30U0lScnKyJMnb29vmft7e3uZccnKyvLy8bOaLFSumsmXL2tTcaB3XPsa1MjMzlZGRYbMAAIAHl10/MsvJyVHDhg31/vvvS5IeffRR/fDDD5o1a5YiIiLs1ldMTIxGjBhht8cHAACFy65HiCpUqKCgoCCbscDAQCUlJUmSfHx8JEkpKSk2NSkpKeacj4+PUlNTbeavXr2qM2fO2NTcaB3XPsa1hgwZovT0dHM5ceLEnW4iAAC4D9g1EDVt2lSHDx+2Gfvpp5/k7+8v6c8TrH18fLRx40ZzPiMjQ7t371ZISIgkKSQkRGlpaUpISDBrNm3apJycHDVu3Nis2bZtm65cuWLWxMXFqUaNGjZXtOVycXGRu7u7zQIAAB5cdg1EAwcO1K5du/T+++/r6NGjWrhwoWbPnq3IyEhJkoODg6KiojR69GitWLFC+/fvV7du3eTr66v27dtL+vOI0jPPPKN//OMf2rNnj3bs2KF+/fqpc+fO8vX1lSS9/PLLcnZ2Vq9evXTgwAEtXrxYU6dOVXR0tL02HQAAFCF2PYfoscce07JlyzRkyBCNHDlSAQEBmjJlirp06WLWDB48WBcuXFDv3r2VlpamJ554QmvXrpWrq6tZs2DBAvXr10+tWrWSo6OjOnbsqA8//NCc9/Dw0Pr16xUZGang4GCVL19eQ4cO5ZJ7AAAgyc6BSJLatm2rtm3b3nTewcFBI0eO1MiRI29aU7ZsWS1cuPCWj1O3bl19/fXXd9wnAAB4cNn9pzsAAADsjUAEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsz66BaPjw4XJwcLBZatasac5fvnxZkZGRKleunEqVKqWOHTsqJSXFZh1JSUkKDw9XiRIl5OXlpUGDBunq1as2NVu2bFGDBg3k4uKiatWqKTY2tjA2DwAA3CfsfoSoVq1a+v33381l+/bt5tzAgQO1cuVKLV26VFu3btWpU6fUoUMHcz47O1vh4eHKysrSzp079emnnyo2NlZDhw41a44fP67w8HC1aNFCiYmJioqK0quvvqp169YV6nYCAICiq5jdGyhWTD4+PnnG09PTNXfuXC1cuFAtW7aUJM2bN0+BgYHatWuXmjRpovXr1+vgwYPasGGDvL29Vb9+fY0aNUpvvfWWhg8fLmdnZ82aNUsBAQGaOHGiJCkwMFDbt2/X5MmTFRYWVqjbCgAAiia7HyE6cuSIfH19VaVKFXXp0kVJSUmSpISEBF25ckWhoaFmbc2aNVWpUiXFx8dLkuLj41WnTh15e3ubNWFhYcrIyNCBAwfMmmvXkVuTu44byczMVEZGhs0CAAAeXHYNRI0bN1ZsbKzWrl2rmTNn6vjx43ryySd17tw5JScny9nZWZ6enjb38fb2VnJysiQpOTnZJgzlzufO3aomIyNDly5dumFfMTEx8vDwMBc/P7+7sbkAAKCIsutHZm3atDH/XbduXTVu3Fj+/v5asmSJ3Nzc7NbXkCFDFB0dbd7OyMggFAEA8ACz+0dm1/L09NQjjzyio0ePysfHR1lZWUpLS7OpSUlJMc858vHxyXPVWe7t29W4u7vfNHS5uLjI3d3dZgEAAA+uIhWIzp8/r59//lkVKlRQcHCwihcvro0bN5rzhw8fVlJSkkJCQiRJISEh2r9/v1JTU82auLg4ubu7KygoyKy5dh25NbnrAAAAsGsg+uc//6mtW7fql19+0c6dO/X3v/9dTk5Oeumll+Th4aFevXopOjpamzdvVkJCgnr06KGQkBA1adJEktS6dWsFBQWpa9eu+u6777Ru3Tq9++67ioyMlIuLiyTptdde07FjxzR48GAdOnRIM2bM0JIlSzRw4EB7bjoAAChC7HoO0W+//aaXXnpJf/zxhx566CE98cQT2rVrlx566CFJ0uTJk+Xo6KiOHTsqMzNTYWFhmjFjhnl/JycnrVq1Sn379lVISIhKliypiIgIjRw50qwJCAjQ6tWrNXDgQE2dOlUVK1bUnDlzuOQeAACY7BqIFi1adMt5V1dXTZ8+XdOnT79pjb+/v7766qtbrqd58+b69ttv76hHAADw4CtS5xABAADYA4EIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYXr5+3DU6OjrfK5w0adIdNwMAAGAP+QpE+f2leAcHh7/UDAAAgD3kKxBt3rz5XvcBAABgN5xDBAAALC9fR4iudeHCBY0dO1YbN25UamqqcnJybOaPHTt215oDAAAoDAUORK+++qq2bt2qrl27qkKFCpw3BAAA7nsFDkRr1qzR6tWr1bRp03vRDwAAQKEr8DlEZcqUUdmyZe9FLwAAAHZR4EA0atQoDR06VBcvXrwX/QAAABS6fH1k9uijj9qcK3T06FF5e3urcuXKKl68uE3tN998c3c7BAAAuMfyFYjat29/j9sAAACwn3wFomHDht3rPgAAAOyGL2YEAACWV+DL7rOzszV58mQtWbJESUlJysrKspk/c+bMXWsOAACgMBT4CNGIESM0adIkderUSenp6YqOjlaHDh3k6Oio4cOH34MWAQAA7q0CB6IFCxbok08+0ZtvvqlixYrppZde0pw5czR06FDt2rXrXvQIAABwTxU4ECUnJ6tOnTqSpFKlSik9PV2S1LZtW61evfrudgcAAFAIChyIKlasqN9//12SVLVqVa1fv16StHfvXrm4uNzd7gAAAApBgQPR3//+d23cuFGS1L9/f7333nuqXr26unXrpp49e971BgEAAO61Al9lNnbsWPPfnTp1kr+/v3bu3Knq1aurXbt2d7U5AACAwlDgQHS9Jk2aqEmTJnejFwAAALso8EdmTk5OatGiRZ7vG0pJSZGTk9NdawwAAKCwFDgQGYahzMxMNWzYUAcOHMgzd6fGjh0rBwcHRUVFmWOXL19WZGSkypUrp1KlSqljx45KSUmxuV9SUpLCw8NVokQJeXl5adCgQbp69apNzZYtW9SgQQO5uLioWrVqio2NveM+AQDAg6fAgcjBwUH/93//p3bt2ikkJERffvmlzdyd2Lt3rz7++GPVrVvXZnzgwIFauXKlli5dqq1bt+rUqVPq0KGDOZ+dna3w8HBlZWVp586d+vTTTxUbG6uhQ4eaNcePH1d4eLhatGihxMRERUVF6dVXX9W6devuqFcAAPDguaMjRE5OTpo6daomTJigTp06afTo0Xd8dOj8+fPq0qWLPvnkE5UpU8YcT09P19y5czVp0iS1bNlSwcHBmjdvnnbu3Gl+AeT69et18OBBzZ8/X/Xr11ebNm00atQoTZ8+3fxJkVmzZikgIEATJ05UYGCg+vXrp+eff16TJ0++o34BAMCD5y/9uGvv3r21Zs0aTZkyRd26dbujdURGRio8PFyhoaE24wkJCbpy5YrNeM2aNVWpUiXFx8dLkuLj41WnTh15e3ubNWFhYcrIyDA/zouPj8+z7rCwMHMdN5KZmamMjAybBQAAPLgKHIj8/f1tTp5u0aKFdu3apRMnThT4wRctWqRvvvlGMTExeeaSk5Pl7OwsT09Pm3Fvb28lJyebNdeGodz53Llb1WRkZOjSpUs37CsmJkYeHh7m4ufnV+BtAwAA948CB6Ljx4+rXLlyNmPVqlXTt99+q2PHjuV7PSdOnNAbb7yhBQsWyNXVtaBt3FNDhgxRenq6udxJ2AMAAPePO/4eoqysLKWmpionJ8ccK8hJ1QkJCUpNTVWDBg3MsezsbG3btk3Tpk3TunXrlJWVpbS0NJujRCkpKfLx8ZEk+fj4aM+ePTbrzb0K7dqa669MS0lJkbu7u9zc3G7Ym4uLCz9DAgCAhRT4CNFPP/2kJ598Um5ubvL391dAQIACAgJUuXJlBQQE5Hs9rVq10v79+5WYmGguDRs2VJcuXcx/Fy9e3PyZEEk6fPiwkpKSFBISIkkKCQnR/v37lZqaatbExcXJ3d1dQUFBZs2168ityV0HAABAgY8Q9ejRQ8WKFdOqVatUoUKFO77UvnTp0qpdu7bNWMmSJVWuXDlzvFevXoqOjlbZsmXl7u6u/v37KyQkxPxm7NatWysoKEhdu3bV+PHjlZycrHfffVeRkZHmEZ7XXntN06ZN0+DBg9WzZ09t2rRJS5Ys0erVq++obwAA8OApcCBKTExUQkKCataseS/6sTF58mQ5OjqqY8eOyszMVFhYmGbMmGHOOzk5adWqVerbt69CQkJUsmRJRUREaOTIkWZNQECAVq9erYEDB2rq1KmqWLGi5syZo7CwsHvePwAAuD8UOBAFBQXp9OnT96IXbdmyxea2q6urpk+frunTp9/0Pv7+/vrqq69uud7mzZvr22+/vRstAgCAB1CBzyEaN26cBg8erC1btuiPP/7g+3oAAMB9r8BHiHK/5LBVq1Y244ZhyMHBQdnZ2XenMwAAgEJS4EC0efPmm87t37//LzUDAABgDwUORM2aNbO5fe7cOX3xxReaM2eOEhIS1K9fv7vWHAAAQGG4498y27ZtmyIiIlShQgVNmDBBLVu2NH90FQAA4H5SoCNEycnJio2N1dy5c5WRkaEXX3xRmZmZWr58uflFiAAAAPebfB8hateunWrUqKHvv/9eU6ZM0alTp/TRRx/dy94AAAAKRb6PEK1Zs0YDBgxQ3759Vb169XvZEwAAQKHK9xGi7du369y5cwoODlbjxo01bdq0e/YFjQAAAIUp34GoSZMm+uSTT/T777+rT58+WrRokXx9fZWTk6O4uDidO3fuXvYJAABwzxT4KrOSJUuqZ8+e2r59u/bv368333xTY8eOlZeXl5599tl70SMAAMA9dceX3UtSjRo1NH78eP3222/64osv7lZPAAAAheovBaJcTk5Oat++vVasWHE3VgcAAFCo7kogAgAAuJ8RiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOXZNRDNnDlTdevWlbu7u9zd3RUSEqI1a9aY85cvX1ZkZKTKlSunUqVKqWPHjkpJSbFZR1JSksLDw1WiRAl5eXlp0KBBunr1qk3Nli1b1KBBA7m4uKhatWqKjY0tjM0DAAD3CbsGoooVK2rs2LFKSEjQvn371LJlSz333HM6cOCAJGngwIFauXKlli5dqq1bt+rUqVPq0KGDef/s7GyFh4crKytLO3fu1KeffqrY2FgNHTrUrDl+/LjCw8PVokULJSYmKioqSq+++qrWrVtX6NsLAACKpmL2fPB27drZ3B4zZoxmzpypXbt2qWLFipo7d64WLlyoli1bSpLmzZunwMBA7dq1S02aNNH69et18OBBbdiwQd7e3qpfv75GjRqlt956S8OHD5ezs7NmzZqlgIAATZw4UZIUGBio7du3a/LkyQoLCyv0bQYAAEVPkTmHKDs7W4sWLdKFCxcUEhKihIQEXblyRaGhoWZNzZo1ValSJcXHx0uS4uPjVadOHXl7e5s1YWFhysjIMI8yxcfH26wjtyZ3HQAAAHY9QiRJ+/fvV0hIiC5fvqxSpUpp2bJlCgoKUmJiopydneXp6WlT7+3treTkZElScnKyTRjKnc+du1VNRkaGLl26JDc3tzw9ZWZmKjMz07ydkZHxl7cTAAAUXXY/QlSjRg0lJiZq9+7d6tu3ryIiInTw4EG79hQTEyMPDw9z8fPzs2s/AADg3rJ7IHJ2dla1atUUHBysmJgY1atXT1OnTpWPj4+ysrKUlpZmU5+SkiIfHx9Jko+PT56rznJv367G3d39hkeHJGnIkCFKT083lxMnTtyNTQUAAEWU3QPR9XJycpSZmang4GAVL15cGzduNOcOHz6spKQkhYSESJJCQkK0f/9+paammjVxcXFyd3dXUFCQWXPtOnJrctdxIy4uLuZXAeQuAADgwWXXc4iGDBmiNm3aqFKlSjp37pwWLlyoLVu2aN26dfLw8FCvXr0UHR2tsmXLyt3dXf3791dISIiaNGkiSWrdurWCgoLUtWtXjR8/XsnJyXr33XcVGRkpFxcXSdJrr72madOmafDgwerZs6c2bdqkJUuWaPXq1fbcdAAAUITYNRClpqaqW7du+v333+Xh4aG6detq3bp1evrppyVJkydPlqOjozp27KjMzEyFhYVpxowZ5v2dnJy0atUq9e3bVyEhISpZsqQiIiI0cuRIsyYgIECrV6/WwIEDNXXqVFWsWFFz5szhknsAAGCyayCaO3fuLeddXV01ffp0TZ8+/aY1/v7++uqrr265nubNm+vbb7+9ox4BAMCDr8idQwQAAFDYCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDy7BqIYmJi9Nhjj6l06dLy8vJS+/btdfjwYZuay5cvKzIyUuXKlVOpUqXUsWNHpaSk2NQkJSUpPDxcJUqUkJeXlwYNGqSrV6/a1GzZskUNGjSQi4uLqlWrptjY2Hu9eQAA4D5h10C0detWRUZGateuXYqLi9OVK1fUunVrXbhwwawZOHCgVq5cqaVLl2rr1q06deqUOnToYM5nZ2crPDxcWVlZ2rlzpz799FPFxsZq6NChZs3x48cVHh6uFi1aKDExUVFRUXr11Ve1bt26Qt1eAABQNBWz54OvXbvW5nZsbKy8vLyUkJCgp556Sunp6Zo7d64WLlyoli1bSpLmzZunwMBA7dq1S02aNNH69et18OBBbdiwQd7e3qpfv75GjRqlt956S8OHD5ezs7NmzZqlgIAATZw4UZIUGBio7du3a/LkyQoLCyv07QYAAEVLkTqHKD09XZJUtmxZSVJCQoKuXLmi0NBQs6ZmzZqqVKmS4uPjJUnx8fGqU6eOvL29zZqwsDBlZGTowIEDZs2168ityV3H9TIzM5WRkWGzAACAB1eRCUQ5OTmKiopS06ZNVbt2bUlScnKynJ2d5enpaVPr7e2t5ORks+baMJQ7nzt3q5qMjAxdunQpTy8xMTHy8PAwFz8/v7uyjQAAoGgqMoEoMjJSP/zwgxYtWmTvVjRkyBClp6eby4kTJ+zdEgAAuIfseg5Rrn79+mnVqlXatm2bKlasaI77+PgoKytLaWlpNkeJUlJS5OPjY9bs2bPHZn25V6FdW3P9lWkpKSlyd3eXm5tbnn5cXFzk4uJyV7YNAAAUfXY9QmQYhvr166dly5Zp06ZNCggIsJkPDg5W8eLFtXHjRnPs8OHDSkpKUkhIiCQpJCRE+/fvV2pqqlkTFxcnd3d3BQUFmTXXriO3JncdAADA2ux6hCgyMlILFy7Ul19+qdKlS5vn/Hh4eMjNzU0eHh7q1auXoqOjVbZsWbm7u6t///4KCQlRkyZNJEmtW7dWUFCQunbtqvHjxys5OVnvvvuuIiMjzaM8r732mqZNm6bBgwerZ8+e2rRpk5YsWaLVq1fbbdsBAEDRYdcjRDNnzlR6erqaN2+uChUqmMvixYvNmsmTJ6tt27bq2LGjnnrqKfn4+Oi///2vOe/k5KRVq1bJyclJISEheuWVV9StWzeNHDnSrAkICNDq1asVFxenevXqaeLEiZozZw6X3AMAAEl2PkJkGMZta1xdXTV9+nRNnz79pjX+/v766quvbrme5s2b69tvvy1wjwAA4MFXZK4yAwAAsBcCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDy7BqJt27apXbt28vX1lYODg5YvX24zbxiGhg4dqgoVKsjNzU2hoaE6cuSITc2ZM2fUpUsXubu7y9PTU7169dL58+dtar7//ns9+eSTcnV1lZ+fn8aPH3+vNw0AANxH7BqILly4oHr16mn69Ok3nB8/frw+/PBDzZo1S7t371bJkiUVFhamy5cvmzVdunTRgQMHFBcXp1WrVmnbtm3q3bu3OZ+RkaHWrVvL399fCQkJ+uCDDzR8+HDNnj37nm8fAAC4PxSz54O3adNGbdq0ueGcYRiaMmWK3n33XT333HOSpM8++0ze3t5avny5OnfurB9//FFr167V3r171bBhQ0nSRx99pL/97W+aMGGCfH19tWDBAmVlZenf//63nJ2dVatWLSUmJmrSpEk2wQkAAFhXkT2H6Pjx40pOTlZoaKg55uHhocaNGys+Pl6SFB8fL09PTzMMSVJoaKgcHR21e/dus+app56Ss7OzWRMWFqbDhw/r7NmzN3zszMxMZWRk2CwAAODBVWQDUXJysiTJ29vbZtzb29ucS05OlpeXl818sWLFVLZsWZuaG63j2se4XkxMjDw8PMzFz8/vr28QAAAosopsILKnIUOGKD093VxOnDhh75YAAMA9VGQDkY+PjyQpJSXFZjwlJcWc8/HxUWpqqs381atXdebMGZuaG63j2se4nouLi9zd3W0WAADw4CqygSggIEA+Pj7auHGjOZaRkaHdu3crJCREkhQSEqK0tDQlJCSYNZs2bVJOTo4aN25s1mzbtk1Xrlwxa+Li4lSjRg2VKVOmkLYGAAAUZXYNROfPn1diYqISExMl/XkidWJiopKSkuTg4KCoqCiNHj1aK1as0P79+9WtWzf5+vqqffv2kqTAwEA988wz+sc//qE9e/Zox44d6tevnzp37ixfX19J0ssvvyxnZ2f16tVLBw4c0OLFizV16lRFR0fbaasBAEBRY9fL7vft26cWLVqYt3NDSkREhGJjYzV48GBduHBBvXv3Vlpamp544gmtXbtWrq6u5n0WLFigfv36qVWrVnJ0dFTHjh314YcfmvMeHh5av369IiMjFRwcrPLly2vo0KFccg8AAEx2DUTNmzeXYRg3nXdwcNDIkSM1cuTIm9aULVtWCxcuvOXj1K1bV19//fUd9wkAAB5sRfYcIgAAgMJCIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZnqUA0ffp0Va5cWa6urmrcuLH27Nlj75YAAEARYJlAtHjxYkVHR2vYsGH65ptvVK9ePYWFhSk1NdXerQEAADuzTCCaNGmS/vGPf6hHjx4KCgrSrFmzVKJECf373/+2d2sAAMDOLBGIsrKylJCQoNDQUHPM0dFRoaGhio+Pt2NnAACgKChm7wYKw+nTp5WdnS1vb2+bcW9vbx06dChPfWZmpjIzM83b6enpkqSMjIy73tv58+f/fMzko8rJunzX138nrpz5TdKfvd1sm+n77qHvwkXfhYu+C9eD3PedyF2XYRi3LzYs4OTJk4YkY+fOnTbjgwYNMho1apSnftiwYYYkFhYWFhYWlgdgOXHixG2zgiWOEJUvX15OTk5KSUmxGU9JSZGPj0+e+iFDhig6Otq8nZOTozNnzqhcuXJycHC45/3eiYyMDPn5+enEiRNyd3e3dzv5Rt+Fi74LF30XLvouXPdD34Zh6Ny5c/L19b1trSUCkbOzs4KDg7Vx40a1b99e0p8hZ+PGjerXr1+eehcXF7m4uNiMeXp6FkKnf527u3uRfWLeCn0XLvouXPRduOi7cBX1vj08PPJVZ4lAJEnR0dGKiIhQw4YN1ahRI02ZMkUXLlxQjx497N0aAACwM8sEok6dOul///ufhg4dquTkZNWvX19r167Nc6I1AACwHssEIknq16/fDT8iexC4uLho2LBheT7qK+rou3DRd+Gi78JF34Xrfu37ZhwMIz/XogEAADy4LPHFjAAAALdCIAIAAJZHIAIAAJZHIAIAAJZHIHpATJ8+XZUrV5arq6saN26sPXv22LulW9q2bZvatWsnX19fOTg4aPny5fZuKV9iYmL02GOPqXTp0vLy8lL79u11+PBhe7d1WzNnzlTdunXNL1ALCQnRmjVr7N1WgY0dO1YODg6Kioqydyu3NHz4cDk4ONgsNWvWtHdb+XLy5Em98sorKleunNzc3FSnTh3t27fP3m3dUuXKlfPsbwcHB0VGRtq7tVvKzs7We++9p4CAALm5ualq1aoaNWpU/n53y87OnTunqKgo+fv7y83NTY8//rj27t1r77b+EgLRA2Dx4sWKjo7WsGHD9M0336hevXoKCwtTamqqvVu7qQsXLqhevXqaPn26vVspkK1btyoyMlK7du1SXFycrly5otatW+vChQv2bu2WKlasqLFjxyohIUH79u1Ty5Yt9dxzz+nAgQP2bi3f9u7dq48//lh169a1dyv5UqtWLf3+++/msn37dnu3dFtnz55V06ZNVbx4ca1Zs0YHDx7UxIkTVaZMGXu3dkt79+612ddxcXGSpBdeeMHOnd3auHHjNHPmTE2bNk0//vijxo0bp/Hjx+ujjz6yd2u39eqrryouLk6ff/659u/fr9atWys0NFQnT560d2t37q78eirsqlGjRkZkZKR5Ozs72/D19TViYmLs2FX+STKWLVtm7zbuSGpqqiHJ2Lp1q71bKbAyZcoYc+bMsXcb+XLu3DmjevXqRlxcnNGsWTPjjTfesHdLtzRs2DCjXr169m6jwN566y3jiSeesHcbf9kbb7xhVK1a1cjJybF3K7cUHh5u9OzZ02asQ4cORpcuXezUUf5cvHjRcHJyMlatWmUz3qBBA+Odd96xU1d/HUeI7nNZWVlKSEhQaGioOebo6KjQ0FDFx8fbsTNrSE9PlySVLVvWzp3kX3Z2thYtWqQLFy4oJCTE3u3kS2RkpMLDw22e50XdkSNH5OvrqypVqqhLly5KSkqyd0u3tWLFCjVs2FAvvPCCvLy89Oijj+qTTz6xd1sFkpWVpfnz56tnz55F9se4cz3++OPauHGjfvrpJ0nSd999p+3bt6tNmzZ27uzWrl69quzsbLm6utqMu7m53RdHQm/GUt9U/SA6ffq0srOz8/wEibe3tw4dOmSnrqwhJydHUVFRatq0qWrXrm3vdm5r//79CgkJ0eXLl1WqVCktW7ZMQUFB9m7rthYtWqRvvvnmvjo/oXHjxoqNjVWNGjX0+++/a8SIEXryySf1ww8/qHTp0vZu76aOHTummTNnKjo6Wv/617+0d+9eDRgwQM7OzoqIiLB3e/myfPlypaWlqXv37vZu5bbefvttZWRkqGbNmnJyclJ2drbGjBmjLl262Lu1WypdurRCQkI0atQoBQYGytvbW1988YXi4+NVrVo1e7d3xwhEwB2KjIzUDz/8cN+8I6pRo4YSExOVnp6u//znP4qIiNDWrVuLdCg6ceKE3njjDcXFxeV5N1qUXfsOv27dumrcuLH8/f21ZMkS9erVy46d3VpOTo4aNmyo999/X5L06KOP6ocfftCsWbPum0A0d+5ctWnTRr6+vvZu5baWLFmiBQsWaOHChapVq5YSExMVFRUlX1/fIr+/P//8c/Xs2VMPP/ywnJyc1KBBA7300ktKSEiwd2t3jEB0nytfvrycnJyUkpJiM56SkiIfHx87dfXg69evn1atWqVt27apYsWK9m4nX5ydnc13b8HBwdq7d6+mTp2qjz/+2M6d3VxCQoJSU1PVoEEDcyw7O1vbtm3TtGnTlJmZKScnJzt2mD+enp565JFHdPToUXu3cksVKlTIE5ADAwP1f//3f3bqqGB+/fVXbdiwQf/973/t3Uq+DBo0SG+//bY6d+4sSapTp45+/fVXxcTEFPlAVLVqVW3dulUXLlxQRkaGKlSooE6dOqlKlSr2bu2OcQ7Rfc7Z2VnBwcHauHGjOZaTk6ONGzfeN+eH3E8Mw1C/fv20bNkybdq0SQEBAfZu6Y7l5OQoMzPT3m3cUqtWrbR//34lJiaaS8OGDdWlSxclJibeF2FIks6fP6+ff/5ZFSpUsHcrt9S0adM8XyPx008/yd/f304dFcy8efPk5eWl8PBwe7eSLxcvXpSjo+3LsJOTk3JycuzUUcGVLFlSFSpU0NmzZ7Vu3To999xz9m7pjnGE6AEQHR2tiIgINWzYUI0aNdKUKVN04cIF9ejRw96t3dT58+dt3i0fP35ciYmJKlu2rCpVqmTHzm4tMjJSCxcu1JdffqnSpUsrOTlZkuTh4SE3Nzc7d3dzQ4YMUZs2bVSpUiWdO3dOCxcu1JYtW7Ru3Tp7t3ZLpUuXznN+VsmSJVWuXLkifd7WP//5T7Vr107+/v46deqUhg0bJicnJ7300kv2bu2WBg4cqMcff1zvv/++XnzxRe3Zs0ezZ8/W7Nmz7d3abeXk5GjevHmKiIhQsWL3x0tbu3btNGbMGFWqVEm1atXSt99+q0mTJqlnz572bu221q1bJ8MwVKNGDR09elSDBg1SzZo1i/Trzm3Z+zI33B0fffSRUalSJcPZ2dlo1KiRsWvXLnu3dEubN282JOVZIiIi7N3aLd2oZ0nGvHnz7N3aLfXs2dPw9/c3nJ2djYceesho1aqVsX79enu3dUfuh8vuO3XqZFSoUMFwdnY2Hn74YaNTp07G0aNH7d1WvqxcudKoXbu24eLiYtSsWdOYPXu2vVvKl3Xr1hmSjMOHD9u7lXzLyMgw3njjDaNSpUqGq6urUaVKFeOdd94xMjMz7d3abS1evNioUqWK4ezsbPj4+BiRkZFGWlqavdv6SxwM4z74SkwAAIB7iHOIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAFhWbGysPD09//J6HBwctHz58r+8HgD2QyACcF/r3r272rdvb+82ANznCEQAAMDyCEQAHliTJk1SnTp1VLJkSfn5+en111/X+fPn89QtX75c1atXl6urq8LCwnTixAmb+S+//FINGjSQq6urqlSpohEjRujq1auFtRkACgGBCMADy9HRUR9++KEOHDigTz/9VJs2bdLgwYNtai5evKgxY8bos88+044dO5SWlqbOnTub819//bW6deumN954QwcPHtTHH3+s2NhYjRkzprA3B8A9xI+7Arivde/eXWlpafk6qfk///mPXnvtNZ0+fVrSnydV9+jRQ7t27VLjxo0lSYcOHVJgYKB2796tRo0aKTQ0VK1atdKQIUPM9cyfP1+DBw/WqVOnJP15UvWyZcs4lwm4jxWzdwMAcK9s2LBBMTExOnTokDIyMnT16lVdvnxZFy9eVIkSJSRJxYoV02OPPWbep2bNmvL09NSPP/6oRo0a6bvvvtOOHTtsjghlZ2fnWQ+A+xuBCMAD6ZdfflHbtm3Vt29fjRkzRmXLltX27dvVq1cvZWVl5TvInD9/XiNGjFCHDh3yzLm6ut7ttgHYCYEIwAMpISFBOTk5mjhxohwd/zxdcsmSJXnqrl69qn379qlRo0aSpMOHDystLU2BgYGSpAYNGujw4cOqVq1a4TUPoNARiADc99LT05WYmGgzVr58eV25ckUfffSR2rVrpx07dmjWrFl57lu8eHH1799fH374oYoVK6Z+/fqpSZMmZkAaOnSo2rZtq0qVKun555+Xo6OjvvvuO/3www8aPXp0YWwegELAVWYA7ntbtmzRo48+arN8/vnnmjRpksaNG6fatWtrwYIFiomJyXPfEiVK6K233tLLL7+spk2bqlSpUlq8eLE5HxYWplWrVmn9+vV67LHH1KRJE02ePFn+/v6FuYkA7jGuMgMAAJbHESIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5/x/FIi0YoUaMAAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die Daten sind in etwa gleichmässig verteilt und bedürfen diesbezüglich keiner weiteren Bearbeitung.\n",
        "Wenn die Klassen ungleichmässig verteilt sind, beeinflusst das die Performance eines darauf trainierten Neuronalen Netzes."
      ],
      "metadata": {
        "id": "iMuOAJ-OMgRk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aufgabe 1.3\n",
        "### Wie machen wir die Klassen dem Model verständlich?\n",
        "Die Label Information liegt als String vor. Ein Neuronales Netz arbeitet jedoch in aller Regel nur mit Floats.\n",
        "Ein einfaches übersetzen der Strings in die Floatwerte 0 - 9 hätte zur Folge, dass zB ein Output von 4 näher am Zielwert 5 läge als ein Output von 1. Die 4 ist der 5 aber nicht ähnlicher als die 1.\n",
        "Es ist daher sinnvoll, jedes mögliche Label durch einen eigenen Floatwert 0 - 1 darzustellen, zB 3 -> [0,0,0,1,0,0,0,0,0,0].\n",
        "Dieser Vorgang heisst **One-Hot-Encoding** und sorgt für die saubere Trennung der Label. Ausserdem erlaubt dieses Vorgehen mit Labeln zu arbeiten, die keine Zahlenwerte sind, wie zB \"Hund\", \"Katze\", \"Maus\".\n",
        "\n",
        "Überführen Sie nun die Targetlabel in das One-Hot-Encoding Format.\n"
      ],
      "metadata": {
        "id": "V7ERDreJM5g7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "##############################################\n",
        "############ ENTER YOUR CODE HERE ############\n",
        "##############################################\n",
        "\n",
        "# One-Hot-Encoding der Labels\n",
        "encoder = OneHotEncoder()\n",
        "labels = encoder.fit_transform(mnist.target.reshape(-1, 1))\n",
        "\n",
        "##############################################\n",
        "##############################################\n",
        "##############################################\n",
        "\n",
        "\n",
        "print(\"Shape der One-Hot-Encdoded Labels:\", labels.shape)"
      ],
      "metadata": {
        "id": "F8v5YopXBStS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45647402-ec47-4374-e2c8-7598e06730f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape der One-Hot-Encdoded Labels: (70000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die shape der labels sollte nun (70000, 10) sein."
      ],
      "metadata": {
        "id": "n6iR1CRjPrLf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aufgabe 1.4\n",
        "### Welche Skalierung der Daten ist sinnvoll?\n",
        "Die Input Werte sind zwar schon im float Format, allerdings skalieren Sie von 0-255. Die Erfahrung zeigt, dass Neuronale Netze am besten mit Werten zwischen -1 und 1 bzw zwischen 0 und 1 arbeiten.\n",
        "\n",
        "Reskalieren Sie die Input Daten mithilfe des Min-Max Scaling:\n",
        "$$scaled\\_data = \\frac{{data - \\min(data)}}{{\\max(data) - \\min(data)}} \\cdot 2 - 1\n",
        "$$"
      ],
      "metadata": {
        "id": "-UvO3iiaP04n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Skalierung der Bilddaten auf [-1, 1]\n",
        "mini, maxi = np.min(mnist.data), np.max(mnist.data)\n",
        "print(\"Min/Max vor Skalierung:\", mini, maxi)\n",
        "\n",
        "##############################################\n",
        "############ ENTER YOUR CODE HERE ############\n",
        "##############################################\n",
        "\n",
        "scaled_data = 2*(mnist.data.astype(float) - mini) / (maxi - mini) - 1\n",
        "\n",
        "##############################################\n",
        "##############################################\n",
        "##############################################\n",
        "\n",
        "print(\"Min/Max nach Skalierung:\", np.min(scaled_data), np.max(scaled_data))\n"
      ],
      "metadata": {
        "id": "z1hIR-IvBSqW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec5cac97-c4f8-40fe-ca1a-7b6d69cf64ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min/Max vor Skalierung: 0 255\n",
            "Min/Max nach Skalierung: -1.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Modell & Trainingsloop erstellen\n",
        "In diesem Abschnitt erstellen wir das Modell und die Trainingsloop. Damit definieren wir das Ziel (die zu minimierende Loss Funktion) und den Algorithmus (Model), um dieses Ziel zu erreichen."
      ],
      "metadata": {
        "id": "1WmzUBJj5D6i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stellen Sie zuerst sicher, dass Sie Zugriff auf GPU ressourcen haben, auf denen die Berechnungen bis zu 20x schneller laufen.\n",
        "\n",
        "Zum aktivieren in Google Colab:\n",
        "\n",
        "Runtime -> Change Runtime\n",
        "\n",
        "Hardware Accelerator -> GPU"
      ],
      "metadata": {
        "id": "4diSF3YkN6Ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Prüfen, ob GPU verfügbar ist. Sonst Berechnung auf CPU. Nur NVIDIA GPUs mit CUDA werden unterstützt\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device, \" (= cuda ?)\")"
      ],
      "metadata": {
        "id": "ffxxOe5DETfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "431e3870-1de3-418a-80ab-aac9bae31366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda  (= cuda ?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um auf der GPU zu rechnen, müssen sich sowohl das Model als auch die Trainingsdaten im GPU Speicher befinden. Das erreicht man mit\n",
        "```\n",
        "model.to(device)\n",
        "```\n",
        "bzw\n",
        "```\n",
        "data = data.to(device)\n",
        "```"
      ],
      "metadata": {
        "id": "GzvzDD6thJNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zuerst laden wir den Datensatz als Tensor, mit dem das Model rechnen wird. Wir unterteilen den Datensatz in Trainings- und Testdaten. Dabei wird has Modell so trainiert, dass die Trainingsdaten möglichst gut approximiert werden. Die Performance des fertig trainierten Modells auf neue Daten wird dann mit dem Testdatensatz abgeschätzt."
      ],
      "metadata": {
        "id": "h5YtsiFi8Fk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Laden des MNIST-Datensatzes als pytorch tensoren\n",
        "transform = transforms.ToTensor()\n",
        "training_data = datasets.FashionMNIST(root='data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.FashionMNIST(root='data', train=False, download=True, transform=transform)\n"
      ],
      "metadata": {
        "id": "1qFRUtrYEgpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aufgabe 2.1\n",
        "\n",
        "Hier definieren wir das Modell.\n",
        "Als Klassifizierungsmodell nehmen wir ein einfaches Multi-Layer Perceptron (MLP), welches zu einem gegebenen MNIST Bild die Wahrscheinlichkeit ausgibt, mit der es die Ziffern 0-9 darstellt. Der höchste Score entspricht also der zugeordneten Ziffer.\n",
        "Erstellen Sie ein MLP mit den folgenden Spezifikationen:\n",
        "* Input: B/W-Bilder mit 28x28 pixeln.\n",
        "* 3 hidden layer (fc1 - fc3, fully connected / linear): 64 Knoten, Aktivierung: ReLU\n",
        "* output layer (fc4): 10 Knoten, Aktivierung: keine\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kbVhjxd9PnDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "# Definieren des Models\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Multi-Layer Perceptron (MLP) Neural Network.\n",
        "\n",
        "        This class represents a simple MLP model with 4 fully connected layers.\n",
        "        The input to the network should have a shape of (N_batch, 28*28), where N_batch is the batch size\n",
        "        and 28*28 is the flattened input image size (28x28 pixels).\n",
        "\n",
        "        The network architecture:\n",
        "        - Input layer: Fully connected layer with 64 output units and ReLU activation.\n",
        "        - Hidden layers: Two fully connected layers with 64 output units and ReLU activation for each.\n",
        "        - Output layer: Fully connected layer with 10 output units (representing 10 classes).\n",
        "\n",
        "        The forward() method defines how the input tensor flows through the layers of the network.\n",
        "\n",
        "        Example usage:\n",
        "        >>> model = MLP()\n",
        "        >>> input_data = torch.randn(32, 28*28)  # Assuming batch size of 32\n",
        "        >>> output = model(input_data)\n",
        "\n",
        "        \"\"\"\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 64)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "##############################################\n",
        "############ ENTER YOUR CODE HERE ############\n",
        "##############################################\n",
        "\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(64, 64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "##############################################\n",
        "##############################################\n",
        "##############################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # make sure shape is (N_batch,N_pixel)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "# Alternative methode, die nicht einfach erlaubt den output jedes layers einzusehen\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(28*28, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # make sure shape is (N_batch,N_pixel)\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Das selbe Model koennen wir auch kurz direkt definieren (ausgenommen das reshaping im forward)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(28*28, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 10)\n",
        ")\n",
        "'''\n",
        "model = MLP()"
      ],
      "metadata": {
        "id": "mYZb1_x5EtS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aufgabe 2.2\n",
        "Nun erstellen wir die Trainingsloop, in der das Modell einmal auf allen gegebenen Daten trainiert wird.\n",
        "Vervollständigen Sie die folgende Trainingsloop, indem sie mit dem  model die Vorhersage berechnen und mithilfe der *criterion* funktion den loss berechnen, der die Vorhersage mit den tatsächlichen Labeln vergleicht.\n",
        "\n",
        "Nachdem der Loss berechnet wurde, können damit die Gradienten für das Parameterupdate im Backward-Prozess berechnet werden:\n",
        "\n",
        "```\n",
        "loss.backward()\n",
        "```\n",
        "\n",
        "Die entsprechenden Updates der Gewichte werden dann mit dem gewählten optimizer Algorithmus angewendet:\n",
        "```\n",
        "optimizer.step()\n",
        "```\n",
        "\n",
        "\n",
        "Im Deep Learning sind die Datensätze zu gross, als dass ein Model auf allen Daten gleichzeitig trainieren könnte. Deswegen verwenden wir einen Dataloader, der den Datensatz in viele kleine Bündel (batches) aufteilt, die dann eins nach dem anderen geladen und das Modell darauf trainiert wird. Die Reihenfolge der Daten sollte während des Trainings in jeder Epoche zufällig gewählt werden."
      ],
      "metadata": {
        "id": "EmI-bKBlfIuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Trainingsloop\n",
        "def train(model: nn.Module,\n",
        "          criterion: nn.Module,\n",
        "          optimizer: optim.Optimizer,\n",
        "          data_loader: DataLoader,\n",
        "          show_progress: bool = True) -> None:\n",
        "    \"\"\"\n",
        "    Train the given model using the provided data_loader and optimization parameters.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to be trained.\n",
        "        criterion: The loss function used for optimization.\n",
        "        optimizer: The optimization algorithm (e.g., SGD, Adam) for updating model parameters.\n",
        "        data_loader (DataLoader): The DataLoader providing the training data in batches.\n",
        "        show_progress (bool, optional): If True, show a progress bar during training. Default is True.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Example usage:\n",
        "        >>> model = MLP()\n",
        "        >>> criterion = nn.CrossEntropyLoss()\n",
        "        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "        >>> train(model, criterion, optimizer, train_data_loader, show_progress=True)\n",
        "    \"\"\"\n",
        "    model.train() # make sure model is in training mode\n",
        "    for images, labels in tqdm(data_loader, desc=\"Train\", disable=not show_progress):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "##############################################\n",
        "############ ENTER YOUR CODE HERE ############\n",
        "##############################################\n",
        "\n",
        "        predictions = model(images)\n",
        "        loss = criterion(predictions, labels)\n",
        "\n",
        "##############################################\n",
        "##############################################\n",
        "##############################################\n",
        "\n",
        "\n",
        "        optimizer.zero_grad() # remove all gradients computed before\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "aO0lKO2pE5-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um den Trainingsprozess nachzuverfolgen, betrachten wir die Entwicklung des Loss über die Epochen hinweg, sowohl für das Trainings als auch das Testset.\n",
        "Um den Stand des Models nach einer Trainingsepoche festzustellen, wird der Loss idealerweise nach beenden des Trainings auf dem gesamten Test oder Trainingsdatensatz berechnet. In der Praxis wird um Ressourcen zu sparen der Trainingloss meist schon während des Trainings gesammelt, was allerdings keine saubere Bewertung der Performance nach der Trainingsepoche ist. Da die Performance aber massgeblich auf dem Testset ermittelt wird, ist dieser Trade-Off berechtigt. Allerdings gilt zu beachten, dass der Loss in diesem Fall nicht stetig sinkt.\n",
        "\n",
        "Wenn kein Training stattfindet, braucht der Gradient für das Parameterupdate nicht berechnet werden, was einen Grossteil der Rechenressourcen ausmacht.\n",
        "Mit *torch.no_grad()* kann diese Berechnung unterbunden und Ressourcen geschont werden."
      ],
      "metadata": {
        "id": "MGEAyhzfinXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Berechnung des Losses auf einem Dataset, ohne Training des Models\n",
        "def compute_average_loss(model: nn.Module,\n",
        "                         criterion: nn.Module,\n",
        "                         data_loader: DataLoader,\n",
        "                         show_progress: bool = True) -> float:\n",
        "    \"\"\"\n",
        "    Compute the average loss on the given dataset using the provided model and loss function.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model used for computing the loss.\n",
        "        criterion (nn.Module): The loss function used for calculating the loss.\n",
        "        data_loader (DataLoader): The DataLoader providing the dataset in batches.\n",
        "        show_progress (bool, optional): If True, show a progress bar during computation. Default is True.\n",
        "\n",
        "    Returns:\n",
        "        float: The average loss per image in the dataset.\n",
        "\n",
        "    Example usage:\n",
        "        >>> model = MLP()\n",
        "        >>> criterion = nn.CrossEntropyLoss()\n",
        "        >>> average_loss = compute_average_loss(model, criterion, validation_data_loader, show_progress=True)\n",
        "    \"\"\"\n",
        "    model.eval() # put model in evaluation mode, where it works as intended for its application\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(data_loader, desc=\"Compute Loss\", disable=not show_progress):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            predictions = model(images)\n",
        "            loss = criterion(predictions, labels)\n",
        "\n",
        "            total_loss += loss.item() * images.size(0)  # loss.item() gibt den floatwert des losses aus. loss ist noch ein tensor\n",
        "            total_samples += images.size(0)\n",
        "\n",
        "    average_loss = total_loss / total_samples # average loss per image\n",
        "    return average_loss"
      ],
      "metadata": {
        "id": "P_62_snaFANV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aufgabe 2.3\n",
        "\n",
        "Nun testen wir Model und Trainingsloop indem wir für zwei Epochen trainieren um zu testen, ob der Trainingsloss sich verringert.\n",
        "Vervollständigen Sie den Code, indem Sie die Loss Funktion *criterion*, den *optimizer* Algorithmus sowie den *Dataloader* fürs Training definieren.\n",
        "\n",
        "Verwenden Sie Cross Entropy loss, den Adam Optimizer mit Defaultwerten, und einen Dataloader mit batchsize 256, der die Trainingsdaten in jedem durchlauf neu mischt."
      ],
      "metadata": {
        "id": "FCBexkp7k16V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "# Testen des Modells und des Trainingsloops\n",
        "model = MLP()\n",
        "model.to(device)\n",
        "\n",
        "##############################################\n",
        "############ ENTER YOUR CODE HERE ############\n",
        "##############################################\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "training_loader = DataLoader(training_data, batch_size=256, shuffle=True)\n",
        "\n",
        "##############################################\n",
        "##############################################\n",
        "##############################################\n",
        "\n",
        "for i in range(2):  # Trainieren für 2 Epochen\n",
        "    train(model, criterion, optimizer, training_loader)\n",
        "    loss = compute_average_loss(model, criterion, training_loader)\n",
        "    print(f\"\\nepoch {i}: {loss:.4f}\\n\")"
      ],
      "metadata": {
        "id": "vZE1FyZP3NfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Der Loss sollte mit jeder Trainingsepoche sinken"
      ],
      "metadata": {
        "id": "EmiDFSPFCjwv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Evaluieren\n",
        "In diesem Abschnitt erstellen wir eine Methode zur Bewertung des Modells.\n",
        "Um die Leistung eines Modells zu bewerten, muss eine passende Metrik gewählt werden, welche die Erfüllung des Ziels nachvollziehbar misst.\n"
      ],
      "metadata": {
        "id": "Z9La9BjQ4ML5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In der Klassifikation ist die naheliegendste Metrik die Accuracy, welche den Anteil korrekter Klassifikationen zeigt\n",
        "\n",
        "$$\\text{Accuracy} = \\frac{\\text{Anzahl korrekter Klassifizierungen}}{\\text{Anzahl Datenpunkte}}$$\n",
        "\n",
        "Allerdings ist die Accuracy mit Vorsicht zu geniessen, insbesondere bei unbalancierten Datensätzen. Beispiel: 90% Klasse 1, 10% Klasse 0. Model sagt immer 1 und bekommt damit 90% accuracy.\n",
        "Ausserdem liefert diese Metrik bei mehreren Klassen keine Einsicht, welche Klassen problematischer sind als andere.\n",
        "\n",
        "\n",
        "Die Alternative dazu ist die Konfusionsmatrix, welche eine genauere Darstellung über die korrekte Zuordnung erlaubt.\n",
        "\n",
        "![Konfusionsmatrix](https://www.researchgate.net/publication/336402347/figure/fig3/AS:812472659349505@1570719985505/Calculation-of-Precision-Recall-and-Accuracy-in-the-confusion-matrix.ppm)\n",
        "\n",
        "Aus Precision, dem Anteil richtiger Daten die erkannt wurden, und Recall, dem Anteil erkannter Daten die tatsächlich richtig sind, lässt sich der F1-score berechnen, welcher beide Aspekte gleichermassen berücksichtigt\n",
        "\n",
        "$$ F1 = 2\\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
        "\n",
        "Alle vier Grössen können Werte zwischen 0 und 1 bzw 0 % und 100 % annehmen, wobei 100 % ein perfektes Ergebnis darstellt.\n",
        "\n",
        "\n",
        "Berechnen Sie mit den richtigen sowie den verhorgesagten Labeln den *F1-Score* sowie die *Konfusionsmatrix*"
      ],
      "metadata": {
        "id": "_cHet7ee3oa9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "\n",
        "def evaluate(model: nn.Module,\n",
        "             data_loader: DataLoader,\n",
        "             show_progress: bool = True) -> tuple:\n",
        "    \"\"\"\n",
        "    Evaluate the given model on the provided data_loader and compute the confusion matrix and F1 score.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to be evaluated.\n",
        "        data_loader (DataLoader): The DataLoader providing the evaluation data in batches.\n",
        "        show_progress (bool, optional): If True, show a progress bar during evaluation. Default is True.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the confusion matrix (as a 2D array) and the F1 score (as a float).\n",
        "\n",
        "    Example usage:\n",
        "        >>> model = MLP()\n",
        "        >>> test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "        >>> conf_mat, f1 = evaluate(model, test_loader)\n",
        "        >>> print(f'F1 score: {f1}')\n",
        "        >>> plot_confusion_matrix(conf_mat)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(data_loader, desc=\"Evaluate\", disable=not show_progress):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_labels.append(labels.cpu())\n",
        "            all_preds.append(preds.cpu())\n",
        "    all_labels = torch.cat(all_labels)\n",
        "    all_preds = torch.cat(all_preds)\n",
        "\n",
        "\n",
        "##############################################\n",
        "############ ENTER YOUR CODE HERE ############\n",
        "##############################################\n",
        "\n",
        "    conf_mat = confusion_matrix(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "##############################################\n",
        "##############################################\n",
        "##############################################\n",
        "\n",
        "    return conf_mat, f1\n",
        "\n",
        "def plot_confusion_matrix(conf_mat: np.ndarray) -> None:\n",
        "    \"\"\"\n",
        "    Plot the confusion matrix using a heatmap.\n",
        "\n",
        "    Args:\n",
        "        conf_mat (np.ndarray): The confusion matrix as a 2D numpy array.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Example usage:\n",
        "        >>> conf_mat = np.array([[10, 2, 3], [1, 15, 1], [2, 2, 8]])\n",
        "        >>> plot_confusion_matrix(conf_mat)\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted labels\")\n",
        "    plt.ylabel(\"True labels\")\n",
        "\n",
        "# Testen der Evaluationsmethode\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "model = MLP().to(device)\n",
        "conf_mat, f1 = evaluate(model, test_loader)\n",
        "print(f'F1 score: {f1}')\n",
        "plot_confusion_matrix(conf_mat)"
      ],
      "metadata": {
        "id": "C_IKqQNx3U04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Für mehrere Klassen zeigt die Konfusionsmatrix, wie oft eine Klasse richtig zugeordnet wird bzw mit welcher anderen Klasse sie wie oft verwechselt wird."
      ],
      "metadata": {
        "id": "8n6EQbGavPlU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Overfitten\n",
        "In diesem Abschnitt versuchen wir, das Modell auf einer einzigen Batch zu überanpassen, sprich einen perfekten Evaluationsscore für diese Batch zu bekommen.\n",
        "Dies ist ein nützlicher Test, um schnell sicherzustellen, dass das Modell in der Lage ist, die Aufgabe zu bewältigen.\n"
      ],
      "metadata": {
        "id": "gCKE8ot8GJmL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Erstellen Sie den Code um das Model auf einer einzigen Batch zu overfitten indem es 100 mal auf der selben Batch trainiert wird. Verwenden Sie dabei die weiter oben definierte Funktion\n",
        "```\n",
        "train(model, criterion, optimizer, dataloader, show_progress=False)\n",
        "```\n",
        "Beachten Sie, dass dataloader eine beliebige Iterable sein kann, welche pro iteration ein tupel (images, labels) ausgibt."
      ],
      "metadata": {
        "id": "aFt6_tNzAWnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "model = MLP().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "training_loader = DataLoader(training_data, batch_size=256, shuffle=True)\n",
        "\n",
        "\n",
        "##############################################\n",
        "############ ENTER YOUR CODE HERE ############\n",
        "##############################################\n",
        "\n",
        "# Get one batch from the training_loader\n",
        "images, labels = next(iter(training_loader))\n",
        "\n",
        "# Train the model on the batch for 100 iterations\n",
        "for _ in range(100):\n",
        "    train(model, criterion, optimizer, [(images, labels)], show_progress=False)\n",
        "\n",
        "##############################################\n",
        "##############################################\n",
        "##############################################\n",
        "\n",
        "# Evaluate the model on the overfitted batch\n",
        "conf_mat, f1 = evaluate(model, [(images, labels)])\n",
        "print(f'\\nResults on overfitted batch:')\n",
        "print(f'\\nF1 score: {f1}\\n')\n",
        "plot_confusion_matrix(conf_mat)\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model on the test_loader\n",
        "conf_mat, f1 = evaluate(model, test_loader)\n",
        "print(f'\\nResults on the test set:')\n",
        "print(f'\\nF1 score: {f1}\\n')\n",
        "plot_confusion_matrix(conf_mat)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VE8P2bmmJ2yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Auf dem overfitted batch sollte das Model einen F1-score von 1 erreichen, die eine Batch also perfekt fitten.\n",
        "\n",
        "Da es sich bein MNIST um einen sehr einfachen Datensatz handelt, zeigt das Model trotz overfit eine recht gute Performance auf den Testdaten."
      ],
      "metadata": {
        "id": "QVc_jq-6VNde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Regularisieren\n",
        " In diesem Abschnitt regularisieren wir das Model, um Overfitting zu verhindern und das Model robuster zu machen."
      ],
      "metadata": {
        "id": "OqjUlkXTG34a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aufgabe 5.1\n",
        "Zuerst verwenden wir Dropout layer, um das Model zu mehr Redundanz zu zwingen.\n",
        "```\n",
        "nn.Dropout(0.5)\n",
        "```\n",
        "In diesem Layer wird in jedem Aufruf zufällig ausgewählt die Hälfte der Outputs des vorherigen Layers auf 0 gesetzt. Damit wird das Modell gezwungen die extrahierten Informationen auf mehrere Nodes zu veirteilen, um nicht von einzelnen Knoten abhängig zu sein.\n",
        "\n",
        "Diese Funktion ist allerdings nur dann aktiv, wenn das Model im Trainingsmodus ist\n",
        "```\n",
        "model.train()\n",
        "```\n",
        "Die Funktion ist ausgeschaltet im Evaluationsmodus, um die volle Performance des Modells zu erreichen.\n",
        "```\n",
        "model.eval()\n",
        "```\n",
        "Es ist sinnvoll, diese Aufrufe standardmässig zu Beginn jeder Trainings- bzw Evaluationsfunktion zu setzen.\n",
        "\n",
        "Vervollständigen Sie jetzt das folgende Modell, indem Sie an jedem hidden layer ein Dropout layer anhängen.\n",
        "\n"
      ],
      "metadata": {
        "id": "h61MhBk7xEUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MLP_regularized(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Multi-Layer Perceptron (MLP) Neural Network with Dropout Regularization.\n",
        "\n",
        "        This class represents an MLP model with 3 fully connected hidden layers, each followed by\n",
        "        a ReLU activation and dropout regularization. The output layer is a fully connected layer\n",
        "        with 10 output units (representing 10 classes).\n",
        "\n",
        "        The input to the network should have a shape of (N_batch, 28*28), where N_batch is the batch size\n",
        "        and 28*28 is the flattened input image size (28x28 pixels).\n",
        "\n",
        "        Architecture:\n",
        "        - Input layer: Fully connected layer with 64 output units and ReLU activation.\n",
        "        - Dropout layer (p=0.5): Regularizes the network during training by randomly zeroing out inputs.\n",
        "        - Hidden layer 1: Fully connected layer with 64 output units and ReLU activation.\n",
        "        - Dropout layer (p=0.5): Regularizes the network during training by randomly zeroing out inputs.\n",
        "        - Hidden layer 2: Fully connected layer with 64 output units and ReLU activation.\n",
        "        - Dropout layer (p=0.5): Regularizes the network during training by randomly zeroing out inputs.\n",
        "        - Output layer: Fully connected layer with 10 output units (representing 10 classes).\n",
        "\n",
        "        The forward() method defines how the input tensor flows through the layers of the network.\n",
        "\n",
        "        Example usage:\n",
        "        >>> model = MLP_regularized()\n",
        "        >>> input_data = torch.randn(32, 28*28)  # Assuming batch size of 32\n",
        "        >>> output = model(input_data)\n",
        "\n",
        "        \"\"\"\n",
        "        super(MLP_regularized, self).__init__()\n",
        "\n",
        "##############################################\n",
        "############ ENTER YOUR CODE HERE ############\n",
        "##############################################\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(28*28, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "\n",
        "##############################################\n",
        "##############################################\n",
        "##############################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "nfJnoJVVwiml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um dieses Model mit der unregularisierten Version zu vergleichen, müssen wir bei beiden ein längeres Training durchführen. Dabei wollen wir den Fortschritt beider Modelle in der Lossfunktion als auch im F1-score vergleichen. Dieses sowohl auf den Trainingsdaten, um den Trainingsfortschritt zu vergleichen, als auch auf den Testdaten, um die Genralisation zu vergleichen. Dazu bedienen wir uns folgender Funktion."
      ],
      "metadata": {
        "id": "L4mq0L4Rq2YH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import trange\n",
        "\n",
        "def full_training(model: nn.Module,\n",
        "                  criterion: nn.Module,\n",
        "                  optimizer: optim.Optimizer,\n",
        "                  train_loader: DataLoader,\n",
        "                  test_loader: DataLoader,\n",
        "                  epochs: int = 10) -> tuple:\n",
        "    \"\"\"\n",
        "    Perform full training of the given model using the provided data and optimization parameters.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The neural network model to be trained.\n",
        "        criterion (nn.Module): The loss function used for optimization.\n",
        "        optimizer (Optimizer): The optimization algorithm (e.g., SGD, Adam) for updating model parameters.\n",
        "        train_loader (DataLoader): The DataLoader providing the training data in batches.\n",
        "        test_loader (DataLoader): The DataLoader providing the validation (test) data in batches.\n",
        "        epochs (int, optional): The number of training epochs. Default is 10.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing lists of training losses, validation losses, training F1 scores, and validation F1 scores.\n",
        "\n",
        "    Example usage:\n",
        "        >>> model = MLP()\n",
        "        >>> criterion = nn.CrossEntropyLoss()\n",
        "        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "        >>> train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "        >>> test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "        >>> losses_train, losses_valid, f1_scores_train, f1_scores_valid = full_training(model, criterion, optimizer, train_loader, test_loader)\n",
        "    \"\"\"\n",
        "    # perform first evaluation on untrained model, for completeness. Is usually skipped\n",
        "    f1_scores_train = [evaluate(model, train_loader, show_progress=False)[1]]\n",
        "    f1_scores_valid = [evaluate(model, test_loader, show_progress=False)[1]]\n",
        "    losses_train = [compute_average_loss(model, criterion, train_loader, show_progress=False)]\n",
        "    losses_valid = [compute_average_loss(model, criterion, test_loader, show_progress=False)]\n",
        "\n",
        "    for epoch in trange(epochs, desc=\"Training epochs\"):\n",
        "        train(model, criterion, optimizer, train_loader, show_progress=False)\n",
        "\n",
        "        losses_train.append(compute_average_loss(model, criterion, train_loader, show_progress=False))\n",
        "        losses_valid.append(compute_average_loss(model, criterion, test_loader, show_progress=False))\n",
        "        f1_scores_train.append(evaluate(model, train_loader, show_progress=False)[1])\n",
        "        f1_scores_valid.append(evaluate(model, test_loader, show_progress=False)[1])\n",
        "\n",
        "    return losses_train, losses_valid, f1_scores_train, f1_scores_valid\n"
      ],
      "metadata": {
        "id": "TBzY7HW3rhmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Als nächstes wollen wir eine L2 Regularisierung einführen, welche die Werte der Gewichte klein hält und so ein entarten des Modells verhindert und es robuster macht.\n",
        "\n",
        "$$L2 = \\lambda \\sum_{i=1}^{n} \\theta_i^2$$\n",
        "\n",
        "Erstellen Sie dazu einen regulisierenden Optimizer.\n",
        "\n",
        "Dann vergleichen wir den Lernprozess zwischen regularisiertem und nicht-regularsiertem Modell."
      ],
      "metadata": {
        "id": "xg54ZImzg6TZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the number of epochs\n",
        "epochs = 3\n",
        "\n",
        "# Initialize the models\n",
        "model = MLP().to(device)\n",
        "model_reg = MLP_regularized().to(device)\n",
        "\n",
        "# Initialize the optimizers\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "##############################################\n",
        "############ ENTER YOUR CODE HERE ############\n",
        "##############################################\n",
        "\n",
        "optimizer_reg = optim.Adam(model_reg.parameters(), weight_decay=0.01)  # Use weight decay for regularization\n",
        "\n",
        "##############################################\n",
        "##############################################\n",
        "##############################################\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # Replace CrossEntropy with your specific criterion\n",
        "\n",
        "\n",
        "# Train and evaluate the models\n",
        "losses_train, losses_valid, f1_scores_train, f1_scores_valid = full_training(\n",
        "    model, criterion, optimizer, training_loader, test_loader, epochs=epochs\n",
        ")\n",
        "\n",
        "losses_train_reg, losses_valid_reg, f1_scores_train_reg, f1_scores_valid_reg = full_training(\n",
        "    model_reg, criterion, optimizer_reg, training_loader, test_loader, epochs=epochs\n",
        ")\n",
        "\n",
        "# Plot the graphs\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "# Loss curves\n",
        "axs[0].plot(losses_train, label='Train', color=\"blue\")\n",
        "axs[0].plot(losses_valid, label='Validation', color=\"orange\")\n",
        "axs[0].plot(losses_train_reg, '--', label='Train (Regularized)', color=\"blue\")\n",
        "axs[0].plot(losses_valid_reg, '--', label='Validation (Regularized)', color=\"orange\")\n",
        "axs[0].set_xlabel('Epochs')\n",
        "axs[0].set_ylabel('Loss')\n",
        "axs[0].set_title('Train and Validation Loss')\n",
        "axs[0].legend()\n",
        "\n",
        "# F1-score curves\n",
        "axs[1].plot(f1_scores_train, label='Train', color=\"blue\")\n",
        "axs[1].plot(f1_scores_valid, label='Validation', color=\"orange\")\n",
        "axs[1].plot(f1_scores_train_reg, '--', label='Train (Regularized)', color=\"blue\")\n",
        "axs[1].plot(f1_scores_valid_reg, '--', label='Validation (Regularized)', color=\"orange\")\n",
        "axs[1].set_xlabel('Epochs')\n",
        "axs[1].set_ylabel('F1-Score')\n",
        "axs[1].set_title('Train and Validation F1-Score')\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S05Ujuclj5eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regularisieren ist ein Tradeoff: langsameres Training für bessere Generalisierung auf unbekannte Daten.\n",
        "Hier handelt es sich um ein sehr kleines Modell und einen einfachen Datensatz. Da die Generalisierung auf unbekannte Daten schon beim Overfitten auf eine Batch recht gut war, ist daher die Regularisierung in diesem Fall nicht sehr hilfreich, sondern bremst das Training nur aus. Je grösser das Modell wird, desto wichtiger wird die Regularisierung."
      ],
      "metadata": {
        "id": "AGxS0gwz7iA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Optimieren\n",
        "In diesem Abschnitt wollen wir das Modell weiter optimieren, indem wir verschiedene Werte für die Hyperparameter ausprobieren und diejenigen wählen, die zu den besten Ergebnissen führen.\n",
        "\n"
      ],
      "metadata": {
        "id": "qnN6WFmCHIli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die Hyperparameter sind jene Zahlenwerte, die den Verlauf des Trainings bzw den Aufbau des Modells bestimmen. Bisher haben wir kennengelernt:\n",
        "* Lernrate\n",
        "* batchsize\n",
        "* Anzahl der Hidden Layer\n",
        "* Grösse der Hidden Layer\n",
        "* Weight-Decay faktor\n",
        "* Dropout Faktor\n",
        "\n",
        "Je nach Modell gibt es noch viele weitere Hyperparameter, die optimiert werden können.\n",
        "\n",
        "Neben diesen Parametern gibt es noch viele weitere Optionen um das Modell zu optimieren:\n",
        "* Modelarchitektur verbessern\n",
        "* Regularisieren\n",
        "* Mehr Daten\n",
        "* Datenaugmentation\n",
        "* besserer Optimizer\n",
        "* Gewichtsinitialisierung\n",
        "\n",
        "Je nach Problemstellung gibt es starke Unterschiede, welche Massnahme mehr Verbesserung verspricht.\n",
        "\n"
      ],
      "metadata": {
        "id": "VsEk1zAK5_Bz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aufgabe 6.1\n",
        "Hier wollen wir uns Beispielhalber auf die Optimierung von zwei Hyperparametern konzentrieren: die **Lernrate** und die **Anzahl der hidden Layer**\n",
        "Erstellen Sie dazu ein MLP mit variabler Anzahl von Hidden Layern, welche alle die selbe Grösse haben: 64 Knoten.\n"
      ],
      "metadata": {
        "id": "fZkq9ECz5jQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MLP_var(nn.Module):\n",
        "    def __init__(self, N_layer: int):\n",
        "        \"\"\"\n",
        "        Multi-Layer Perceptron (MLP) Neural Network with Variable Number of Hidden Layers.\n",
        "\n",
        "        This class represents an MLP model with variable number of fully connected hidden layers,\n",
        "        each followed by a ReLU activation function. The output layer is a fully connected layer\n",
        "        with 10 output units (representing 10 classes).\n",
        "\n",
        "        The input to the network should have a shape of (N_batch, 28*28), where N_batch is the batch size\n",
        "        and 28*28 is the flattened input image size (28x28 pixels).\n",
        "\n",
        "        Args:\n",
        "            N_layer (int): The number of hidden layers in the MLP.\n",
        "\n",
        "        Architecture:\n",
        "        - Input layer: Fully connected layer with 64 output units and ReLU activation.\n",
        "        - Hidden layers: N_layer-1 fully connected layers, each with 64 output units and ReLU activation.\n",
        "        - Output layer: Fully connected layer with 10 output units (representing 10 classes).\n",
        "\n",
        "        The forward() method defines how the input tensor flows through the layers of the network.\n",
        "\n",
        "        Example usage:\n",
        "        >>> model = MLP_var(N_layer=3)\n",
        "        >>> input_data = torch.randn(32, 28*28)  # Assuming batch size of 32\n",
        "        >>> output = model(input_data)\n",
        "\n",
        "        \"\"\"\n",
        "        super(MLP_var, self).__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.Linear(28*28, 64))\n",
        "        layers.append(nn.ReLU())\n",
        "\n",
        "##############################################\n",
        "############ ENTER YOUR CODE HERE ############\n",
        "##############################################\n",
        "\n",
        "\n",
        "##############################################\n",
        "##############################################\n",
        "##############################################\n",
        "\n",
        "        layers.append(nn.Linear(64, 10))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.model(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "M5Y7AIQA8zgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aufgabe 6.2\n",
        "Um die Ergebnisse für verschiedene Hyperparameter miteinander zu vergleichen, benötigen wir einen Teil des Datensatzes, auf dem nicht trainiert wurde. Dazu trennen wir vom Trainingsdatensatz einen Teil zur Validation ab. Dieser dient um die Performance des Modells auf unbekannten Daten zu evaluieren, ohne den Testdatensatz zu berühren, auf dem erst ganz zum Schluss das finale Modell evaluiert werden soll.\n",
        "\n",
        "Teilen Sie nun den Trainingsdatensatz in einen Train (80 %) und Validation (20 %) Datensatz auf.\n"
      ],
      "metadata": {
        "id": "Wd4zqilqxAUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# Definiere das Split-Verhältnis\n",
        "train_ratio = 0.8\n",
        "valid_ratio = 0.2\n",
        "\n",
        "# Gesamteanzahl der Trainingsdaten\n",
        "N_training = len(training_data)\n",
        "\n",
        "##############################################\n",
        "############ ENTER YOUR CODE HERE ############\n",
        "##############################################\n",
        "\n",
        "# Berechne die Anzahl der Beispiele für jeden Split\n",
        "train_size = ...\n",
        "valid_size = ...\n",
        "\n",
        "# Teile den Trainingsdatensatz in Train und Valid auf\n",
        "train_data, valid_data = ...\n",
        "\n",
        "##############################################\n",
        "##############################################\n",
        "##############################################\n",
        "\n",
        "training_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=256, shuffle=True)\n"
      ],
      "metadata": {
        "id": "YOfAr3o4KlB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aufgabe 6.3\n",
        "Um geeignete Hyperparameter zu finden führen wir einen Grid_search durch, bei dem wir kleine Listen von Werten systematisch miteinander Paaren, sodass sie ein Gitter Bilden. Mit jedem dieser Paare von Hyperparametern trainieren wir ein Modell und vergleichen den Trainingsfortschritt.\n",
        "\n",
        "Vervollständigen Sie die folgende Funktion, indem Sie das *model*, das *criterion* sowie den *optimizer* definieren."
      ],
      "metadata": {
        "id": "hGj_7x7m7C68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from itertools import product\n",
        "\n",
        "def grid_search(N_layer_values: list,\n",
        "                learning_rate_values: list,\n",
        "                epochs: int = 5) -> None:\n",
        "    \"\"\"\n",
        "    Perform grid search for hyperparameter tuning.\n",
        "\n",
        "    This function performs grid search to find the best combination of the number of hidden layers\n",
        "    and learning rate for an MLP_var model. It trains the model with different hyperparameter values\n",
        "    and plots the F1 score and loss curves for different combinations.\n",
        "\n",
        "    Args:\n",
        "        N_layer_values (list): A list of integers representing the different values for the number of hidden layers.\n",
        "        learning_rate_values (list): A list of floats representing the different values for the learning rate.\n",
        "        epochs (int, optional): The number of training epochs. Default is 10.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Example usage:\n",
        "        >>> N_layer_values = [1, 2, 3]\n",
        "        >>> learning_rate_values = [0.001, 0.01, 0.1]\n",
        "        >>> grid_search(N_layer_values, learning_rate_values)\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for (N_layer, lr) in product(N_layer_values, learning_rate_values):\n",
        "        print(f\"train {N_layer} layers with lr={lr}\")\n",
        "\n",
        "##############################################\n",
        "############ ENTER YOUR CODE HERE ############\n",
        "##############################################\n",
        "\n",
        "        model = ...\n",
        "        model.to(device)\n",
        "        criterion = ...\n",
        "        optimizer = ...\n",
        "\n",
        "##############################################\n",
        "##############################################\n",
        "##############################################\n",
        "\n",
        "        losses_train, losses_valid, f1_scores_train, f1_scores_valid = full_training(\n",
        "            model, criterion, optimizer, training_loader, valid_loader, epochs=epochs\n",
        "        )\n",
        "\n",
        "        axes[0].plot(range(epochs+1), f1_scores_train, label=f'{N_layer} layers, lr={lr}')\n",
        "        axes[1].plot(range(epochs+1), f1_scores_valid, label=f'{N_layer} layers, lr={lr}')\n",
        "        axes[2].plot(range(epochs+1), losses_train, label=f'{N_layer} layers, lr={lr}')\n",
        "        axes[3].plot(range(epochs+1), losses_valid, label=f'{N_layer} layers, lr={lr}')\n",
        "\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('F1 Score (Train)')\n",
        "    axes[0].legend()\n",
        "\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('F1 Score (Test)')\n",
        "    axes[1].legend()\n",
        "\n",
        "    axes[2].set_xlabel('Epoch')\n",
        "    axes[2].set_ylabel('Loss (Train)')\n",
        "    axes[2].legend()\n",
        "\n",
        "    axes[3].set_xlabel('Epoch')\n",
        "    axes[3].set_ylabel('Loss (Test)')\n",
        "    axes[3].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "UeWTxibUB4sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Durchführen der Hyperparametersuche\n",
        "grid_search([1, 2], [0.01, 0.1])\n",
        "#grid_search([2, 4, 6], [0.001, 0.01, 0.1])"
      ],
      "metadata": {
        "id": "zYnL0QBd81-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wie bewerten Sie die Ergebnisse? Welche Hyperparameter sind die geeignesten?"
      ],
      "metadata": {
        "id": "2ADSX44LMeot"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QiRDeh1LGaqk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}