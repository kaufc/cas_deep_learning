{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Vergleich von Regularisierungstechniken bei Convolutional Neural Networks (CNNs)\n",
        "\n",
        "In diesem Notebook werden wir verschiedene Regularisierungstechniken für Convolutional Neural Networks (CNNs) untersuchen, um ihre Auswirkungen auf die Modellleistung zu vergleichen. Wir verwenden den CIFAR-10-Datensatz, um ein einfaches CNN zu trainieren und Regularisierungen wie L1, L2, Dropout und Batch Normalization zu testen. Zusätzlich führen wir ein Hyperparameter-Tuning durch, um die besten Einstellungen für das Modell zu finden. Am Ende visualisieren wir die Ergebnisse und wenden das Modell auf Testbilder an, um seine Performance zu beurteilen.\n",
        "\n",
        "**Nützlicher Tipp:**  \n",
        "Regelmäßiges Experimentieren und Vergleichen von verschiedenen Regularisierungsansätzen ist eine bewährte Methode, um robuste Modelle zu entwickeln, die gut generalisieren. Behalte immer die Überanpassung (Overfitting) im Blick und nutze Regularisierung, um sie zu minimieren.\n"
      ],
      "metadata": {
        "id": "GBiba1GkFMSu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration"
      ],
      "metadata": {
        "id": "6Jgy-d3RFa6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vorbereitung und Datensatz-Import\n",
        "\n",
        "In dieser Zelle importieren wir die notwendigen Bibliotheken und laden den CIFAR-10-Datensatz. Es wird auch überprüft, ob eine GPU verfügbar ist, um die Rechenleistung zu optimieren. Achte darauf, die GPU in deiner Laufzeitumgebung zu aktivieren, um das Training zu beschleunigen."
      ],
      "metadata": {
        "id": "NDJviUlbKLqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aufgabe\n",
        "- Richte deine Rechenumgebung so ein, dass TensorFlow Zugriff auf GPUs hat."
      ],
      "metadata": {
        "id": "RN2JWr7YVYiO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jENhql1QqzUZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Überprüfen, ob eine GPU verfügbar ist und auf die GPU wechseln\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"Using GPU\")\n",
        "else:\n",
        "    print(\"Deutsch:\\nUm die GPU in Colab zu aktivieren, befolge diese Schritte:\\n1. Gehe zum Menü: Runtime > Change runtime type.\\n2. Wähle im erscheinenden Dialogfeld GPU aus dem Dropdown-Menü unter Hardware accelerator aus.\\n3. Klicke auf Save (Speichern).\\n\\nTensorflow verwendet automatisch GPU für aufwendige Rechnungen\")\n",
        "    sys.exit(\"Keine GPU gefunden. Bitte die Runtime auf GPU schalten.\")\n",
        "\n",
        "# CIFAR-10 Datensatz laden\n",
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualisierung der Trainingsdaten\n",
        "\n",
        "Hier visualisieren wir 25 Beispielbilder aus dem CIFAR-10-Datensatz. Dies hilft dir, die Daten besser zu verstehen, bevor wir ein Modell darauf trainieren. Jedes Bild ist mit dem entsprechenden Klassenlabel beschriftet.\n"
      ],
      "metadata": {
        "id": "PUAqJp6sKUTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Klassenlabels für CIFAR-10\n",
        "class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "\n",
        "# Einige Beispielbilder plotten\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):  # 25 Bilder (5x5 Grid)\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.xticks([])  # Keine x-Achsen-Ticks\n",
        "    plt.yticks([])  # Keine y-Achsen-Ticks\n",
        "    plt.grid(False)  # Kein Grid\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)  # Bild plotten\n",
        "    plt.xlabel(class_names[y_train[i][0]])  # Klasse als Label\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sOyAVuYzvo8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modell erstellen & Trainieren"
      ],
      "metadata": {
        "id": "ReuCAGnCHi7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modellarchitektur erstellen\n",
        "\n",
        "In dieser Zelle definieren wir eine flexible Funktion `create_model`, die ein Convolutional Neural Network (CNN) erstellt. Du kannst verschiedene Regularisierungstechniken wie L1, L2, Dropout und Batch Normalization anwenden. Die Lernrate des Optimizers kann ebenfalls angepasst werden.\n",
        "\n",
        "\n",
        "**Nützlicher Tipp:**  \n",
        "Beim Erstellen eines Modells ist es wichtig, mit einer einfachen Architektur zu beginnen und schrittweise Komplexität hinzuzufügen, z.B. durch zusätzliche Schichten oder Regularisierungstechniken. Dies hilft, die Auswirkungen jeder Änderung besser zu verstehen und Overfitting zu vermeiden."
      ],
      "metadata": {
        "id": "eLTS6QzjKjbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aufgabe\n",
        " - Ergänze die `BatchNormalization`-Schicht nach der zweiten und dritten  `Conv2D`-Schicht, wenn `use_batchnorm=True` ist. Diese Schicht normalisiert die Ausgaben der Neuronen und kann das Training stabilisieren.\n",
        " - Ergänze die `Dropout`-Schicht nach der zweiten und dritten 'Pool'-Schicht, wenn `dropout_rate > 0` ist. Dropout hilft, Overfitting zu reduzieren, indem es zufällig Neuronen während des Trainings deaktiviert.\n"
      ],
      "metadata": {
        "id": "kgL7bIRjTES6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Einfache CNN-Architektur definieren\n",
        "def create_model(reg_type=None, reg_strength=0.001, dropout_rate=0.0, use_batchnorm=False, learning_rate=0.001):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Erste Convolutional + Pooling Schicht\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3),\n",
        "                            kernel_regularizer=reg_type(reg_strength) if reg_type else None))\n",
        "    if use_batchnorm:\n",
        "        model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    if dropout_rate > 0:\n",
        "        model.add(layers.Dropout(dropout_rate))\n",
        "\n",
        "    # Zweite Convolutional + Pooling Schicht\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=reg_type(reg_strength) if reg_type else None))\n",
        "\n",
        "##############################################\n",
        "############ ENTER YOUR CODE HERE ############\n",
        "##############################################\n",
        "\n",
        "    if use_batchnorm:\n",
        "        ...\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    if dropout_rate > 0:\n",
        "        ...\n",
        "\n",
        "\n",
        "\n",
        "    # Dritte Convolutional Schicht\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=reg_type(reg_strength) if reg_type else None))\n",
        "    if use_batchnorm:\n",
        "        ...\n",
        "\n",
        "    # Flachlegung + Fully Connected Schicht\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu', kernel_regularizer=reg_type(reg_strength) if reg_type else None))\n",
        "    if dropout_rate > 0:\n",
        "        ...\n",
        "\n",
        "##############################################\n",
        "############ ENTER YOUR CODE HERE ############\n",
        "##############################################\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # Kompilieren des Modells\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "-lCyG__EyjrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training der Modelle mit unterschiedlichen Regularisierungstechniken\n",
        "\n",
        "Wir erstellen und trainieren mehrere Modelle mit verschiedenen Regularisierungsansätzen: ohne Regularisierung, L1, L2, Dropout und Batch Normalization. Jede Technik wird separat getestet, um ihre Wirkung auf die Modellleistung zu untersuchen.\n",
        "\n",
        "**Nützlicher Tipp:**  \n",
        "Regelmäßiges Monitoring der Modellleistung während des Trainings hilft, frühzeitig Anzeichen von Overfitting zu erkennen. Unterschiedliche Regularisierungstechniken haben unterschiedliche Effekte, daher ist es wichtig, sie systematisch zu vergleichen, um die beste Methode für dein Problem zu finden.\n",
        "\n"
      ],
      "metadata": {
        "id": "_CuCfA3zKpoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Modelle mit verschiedenen Regularisierungstechniken erstellen\n",
        "model_no_reg = create_model()\n",
        "model_l2_reg = create_model(reg_type=regularizers.l2)\n",
        "model_l1_reg = create_model(reg_type=regularizers.l1)\n",
        "model_dropout = create_model(dropout_rate=0.5)\n",
        "model_batchnorm = create_model(use_batchnorm=True)\n",
        "\n",
        "# Modelle trainieren\n",
        "print(\"train no reg\")\n",
        "history_no_reg = model_no_reg.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "print(\"train L1 reg\")\n",
        "history_l1_reg = model_l1_reg.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "print(\"train L2 reg\")\n",
        "history_l2_reg = model_l2_reg.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "print(\"train dropout\")\n",
        "history_dropout = model_dropout.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "print(\"train batchnorm\")\n",
        "history_batchnorm = model_batchnorm.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "DhNsgdIxvJMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verschiedene Regularizations vergleichen\n"
      ],
      "metadata": {
        "id": "xZr5D1x2Hm2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualisierung der Trainingsfortschritte\n",
        "\n",
        "Die Trainings- und Validierungsergebnisse werden für jedes Modell visualisiert. Wir vergleichen die Loss- und Accuracy-Werte für jedes Regularisierungsverfahren, um zu sehen, welche Technik am effektivsten ist.\n",
        "\n",
        "**Nützlicher Tipp:**  \n",
        "Das Plotten der Trainings- und Validierungskurven ist entscheidend, um zu sehen, wie gut dein Modell lernt. Achte auf Divergenzen zwischen Trainings- und Validierungskurven, da dies auf Overfitting hinweisen könnte. Vergleiche die Ergebnisse verschiedener Modelle direkt, um zu sehen, welche Regularisierungsmethode am effektivsten ist. Dabei genügt nicht nur ein Blick auf die Accuracy Metrik; auch der Train und Valid Loss sollte stets betrachtet werden.\n"
      ],
      "metadata": {
        "id": "gn6lYcKGKvwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aufgabe\n",
        "- Interpretiere, wie sich verschiedene Regularisierungstechniken auf die Trainings- und Validierungskurven auswirken. Diskutiere, welche Techniken die beste Balance zwischen Bias und Varianz erreichen und Overfitting verhindern."
      ],
      "metadata": {
        "id": "__TxRTRXUZCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Funktionen zum Plotten\n",
        "def plot_metrics(history, title):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Loss\n",
        "    axs[0].plot(history.history['loss'], label='Train Loss')\n",
        "    axs[0].plot(history.history['val_loss'], label='Validation Loss')\n",
        "    axs[0].set_title(f'{title} - Loss')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_ylabel('Loss')\n",
        "    axs[0].set_yscale('log')\n",
        "    axs[0].legend()\n",
        "\n",
        "    # Accuracy\n",
        "    axs[1].plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    axs[1].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    axs[1].set_title(f'{title} - Accuracy')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_ylabel('Accuracy (%)')\n",
        "    axs[1].set_ylim(0, 1)\n",
        "    axs[1].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# No Regularization\n",
        "plot_metrics(history_no_reg, 'No Regularization')\n",
        "\n",
        "\n",
        "# L1 Regularization\n",
        "plot_metrics(history_l1_reg, 'L1 Regularization')\n",
        "\n",
        "# L2 Regularization\n",
        "plot_metrics(history_l2_reg, 'L2 Regularization')\n",
        "\n",
        "# Dropout\n",
        "plot_metrics(history_dropout, 'Dropout')\n",
        "\n",
        "# Batch Normalization\n",
        "plot_metrics(history_batchnorm, 'Batch Normalization')\n",
        "\n",
        "# Plot aller Validation Accuracies\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history_no_reg.history['val_accuracy'], label='No Regularization')\n",
        "plt.plot(history_l1_reg.history['val_accuracy'], label='L1 Regularization')\n",
        "plt.plot(history_l2_reg.history['val_accuracy'], label='L2 Regularization')\n",
        "plt.plot(history_dropout.history['val_accuracy'], label='Dropout')\n",
        "plt.plot(history_batchnorm.history['val_accuracy'], label='Batch Normalization')\n",
        "plt.title('Validation Accuracy for all Regularization Techniques')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Validation Accuracy (%)')\n",
        "plt.ylim(0, 1)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4hbBDAQwrLje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "z31oANpPHu3w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zuerst installieren wir das kerastuner Paket, welches Hyperpamareter Tuning automatisiert."
      ],
      "metadata": {
        "id": "7pu5-WaVK1XC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "id": "fAgQB6lz0P_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter-Tuning mit Keras Tuner\n",
        "\n",
        "Hier tunen wir die Hyperparameter. Dazu definieren wir das `CNNHyperModel`, um den Keras Tuner zu verwenden. Wir können zwischen verschiedenen Regularisierungstypen wählen und die Lernrate sowie die Stärke der Regularisierung optimieren.\n",
        "\n",
        "\n",
        "**Nützlicher Tipp:**  \n",
        "Hyperparameter-Tuning kann zeitaufwändig sein, aber es lohnt sich. Beginne mit einer kleineren Anzahl von Trials, um schnell ein Gefühl für geeignete Parameterbereiche zu bekommen. Verwende logische Schritte bei der Auswahl von Werten (z.B. logarithmische Skalen für Lernraten), um den Suchraum effizienter zu durchsuchen.\n",
        "\n"
      ],
      "metadata": {
        "id": "0NrUrieWK26c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aufgabe\n",
        "- Wähle eine Regularisierungsmethode und führe ein Hyperparametertuning aus"
      ],
      "metadata": {
        "id": "vvMzaK3oWui8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, models, regularizers\n",
        "from kerastuner import HyperModel, RandomSearch\n",
        "import kerastuner as kt\n",
        "\n",
        "# HyperModel Klasse definieren, die die create_model Funktion nutzt\n",
        "class CNNHyperModel(HyperModel):\n",
        "    def __init__(self, reg_type, use_batchnorm=False):\n",
        "        self.reg_type = reg_type\n",
        "        self.use_batchnorm = use_batchnorm\n",
        "\n",
        "    def build(self, hp):\n",
        "        reg_strength = hp.Float('reg_strength', min_value=1e-4, max_value=1e-2, sampling='LOG')\n",
        "        dropout_rate = hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)\n",
        "        learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')\n",
        "\n",
        "        # Passende Regularisierungsparameter je nach gewähltem Regularisierungstyp\n",
        "        if self.reg_type == regularizers.l2 or self.reg_type == regularizers.l1:\n",
        "            return create_model(reg_type=self.reg_type, reg_strength=reg_strength, learning_rate=learning_rate, use_batchnorm=self.use_batchnorm)\n",
        "        else:\n",
        "            return create_model(reg_type=None, dropout_rate=dropout_rate, learning_rate=learning_rate, use_batchnorm=self.use_batchnorm)\n",
        "\n",
        "##############################################\n",
        "############ ENTER YOUR CODE HERE ############\n",
        "##############################################\n",
        "\n",
        "# Regularisation auswählen\n",
        "#hypermodel = CNNHyperModel(reg_type=regularizers.l1)   ## L1\n",
        "#hypermodel = CNNHyperModel(reg_type=regularizers.l2)   ## L2\n",
        "#hypermodel = CNNHyperModel(reg_type=None)              ## Dropout\n",
        "\n",
        "##############################################\n",
        "############ ENTER YOUR CODE HERE ############\n",
        "##############################################\n",
        "\n",
        "# Anzahl an Kombinationen, die getestet werden sollen\n",
        "num_trials = 6\n",
        "\n",
        "# RandomSearch Tuner definieren\n",
        "tuner = RandomSearch(\n",
        "    hypermodel,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=num_trials,  # Anzahl der verschiedenen Konfigurationen, die getestet werden sollen\n",
        "    executions_per_trial=1,  # Anzahl der Trainingsläufe pro Konfiguration\n",
        "    directory='hyperparam_tuning',\n",
        "    project_name='cnn_tuning'\n",
        ")\n",
        "\n",
        "# Hyperparameter-Tuning ausführen\n",
        "tuner.search(x_train, y_train, epochs=3, validation_data=(x_test, y_test))\n",
        "\n",
        "# Beste Hyperparameter anzeigen\n",
        "final_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Beste Regularisierungsstärke: {final_hps.get('reg_strength')}\")\n",
        "print(f\"Beste Dropout-Rate: {final_hps.get('dropout_rate')}\")\n",
        "print(f\"Beste Lernrate: {final_hps.get('learning_rate')}\")\n"
      ],
      "metadata": {
        "id": "_zJ7OYsYsXzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Um neues Tuning zu starten, statt das alte erneut zu betrachten\n",
        "#!rm hyperparam_tuning/cnn_tuning/tuner0.json\n"
      ],
      "metadata": {
        "id": "9YbfOK8IEvQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualisierung der Hyperparameter-Tuning-Ergebnisse\n",
        "\n",
        "Nach dem Hyperparameter-Tuning visualisieren wir die Ergebnisse. Dies zeigt, wie sich verschiedene Lernraten und Regularisierungsstärken auf die Validierungsgenauigkeit auswirken.\n",
        "\n",
        "**Nützlicher Tipp:**  \n",
        "Nach dem Hyperparameter-Tuning ist es hilfreich, die besten Modelle und ihre Hyperparameter zu visualisieren. Dies ermöglicht es dir, nicht nur das beste Modell auszuwählen, sondern auch zu verstehen, wie verschiedene Hyperparameter die Modellleistung beeinflussen, was bei zukünftigen Projekten wertvoll sein kann.\n"
      ],
      "metadata": {
        "id": "UJM2A-Q3LIGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aufgabe\n",
        "- Analysiere die Ergebnisse der Hyperparameter-Suche. Diskutiere, wie sich verschiedene Lernraten und Regularisierungsstärken auf die Modellleistung auswirken und welche Kombination die besten Ergebnisse liefert.\n"
      ],
      "metadata": {
        "id": "HNmOZ2a_Uwyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ergebnisse des Tuners abrufen\n",
        "tuner.results_summary()\n",
        "\n",
        "# Liste der besten Hyperparameter-Kombinationen abrufen\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=num_trials)\n",
        "\n",
        "# Extrahiere die Werte für die Lernrate und die Regularisierungsstärke/Dropout-Rate\n",
        "learning_rates = [hp.get('learning_rate') for hp in best_hps]\n",
        "if hypermodel.reg_type:\n",
        "    reg_strengths = [hp.get('reg_strength') for hp in best_hps]\n",
        "    reg_type = 'Regularisierungsstärke'\n",
        "else:\n",
        "    reg_strengths = [hp.get('dropout_rate') for hp in best_hps]\n",
        "    reg_type = 'Dropout-Rate'\n",
        "\n",
        "# Visualisierung der Ergebnisse\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Plot für Lernrate vs. Validierungsgenauigkeit\n",
        "val_accuracies = [tuner.oracle.get_trial(trial_id).metrics.get_best_value('val_accuracy') for trial_id in tuner.oracle.trials]\n",
        "print(len(learning_rates), len(val_accuracies))\n",
        "ax[0].scatter(learning_rates, val_accuracies)\n",
        "ax[0].set_xlabel('Lernrate')\n",
        "ax[0].set_ylabel('Validation Accuracy')\n",
        "ax[0].set_title('Lernrate vs. Validation Accuracy')\n",
        "ax[0].set_xscale('log')\n",
        "\n",
        "# Plot für Regularisierungsstärke/Dropout-Rate vs. Validierungsgenauigkeit\n",
        "ax[1].scatter(reg_strengths, val_accuracies)\n",
        "ax[1].set_xlabel(reg_type)\n",
        "ax[1].set_ylabel('Validation Accuracy')\n",
        "ax[1].set_title(f'{reg_type} vs. Validation Accuracy')\n",
        "ax[1].set_xscale('log' if reg_type == 'Regularisierungsstärke' else 'linear')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pXXB8vWm3s2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modell trainieren"
      ],
      "metadata": {
        "id": "jpoMemNgH3aC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hier wird das Modell mit den besten während des Hyperparameter-Tunings gefundenen Hyperparametern trainiert. Dies sollte die beste Leistung auf den Testdaten erzielen.\n",
        "\n",
        "**Nützlicher Tipp:**  \n",
        "Wenn du das beste Modell erneut trainierst, speichere die Trainingshistorie und das Modell regelmäßig. Dadurch kannst du den Trainingsfortschritt analysieren und das Modell später einfach laden und weiterverwenden, ohne das Training erneut durchführen zu müssen.\n"
      ],
      "metadata": {
        "id": "B8EOrHEdLMkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bestes Modell erstellen und trainieren\n",
        "model = tuner.hypermodel.build(final_hps)\n",
        "history = model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "jKM2d9Mq0HA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics(history, \"Dropout\")"
      ],
      "metadata": {
        "id": "QIthOkqzNzie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Anwendung des Modells auf Testbilder\n",
        "\n",
        "In dieser Zelle wird das trainierte Modell auf 25 zufällig ausgewählte Testbilder angewendet. Die Bilder werden mit den tatsächlichen Labels und den vorhergesagten Labels angezeigt. Dies hilft dir zu verstehen, wie gut das Modell auf neuen, ungesehenen Daten abschneidet.\n",
        "\n",
        "**Nützlicher Tipp:**  \n",
        "Das Anwenden des Modells auf Testdaten und das Visualisieren der Ergebnisse ist eine hervorragende Methode, um die Leistungsfähigkeit des Modells zu überprüfen. Achte besonders auf die Fehler, die das Modell macht, um zu verstehen, in welchen Klassen oder Szenarien es noch Schwierigkeiten gibt.\n"
      ],
      "metadata": {
        "id": "lPWciWHlLPzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Nimm 25 zufällige Testbilder\n",
        "num_images = 25\n",
        "random_indices = np.random.choice(x_test.shape[0], num_images, replace=False)\n",
        "test_images = x_test[random_indices]\n",
        "test_labels = y_test[random_indices]\n",
        "\n",
        "# Vorhersagen für diese Testbilder\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Erstelle die Plot-Figur\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(num_images):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "\n",
        "    # Zeige das Bild\n",
        "    plt.imshow(test_images[i])\n",
        "\n",
        "    # Echte und vorhergesagte Labels anzeigen\n",
        "    true_label = class_names[test_labels[i][0]]\n",
        "    predicted_label = class_names[np.argmax(predictions[i])]\n",
        "\n",
        "    plt.title(f\"True: {true_label}\\nPred: {predicted_label}\", color='blue' if true_label == predicted_label else 'red')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "obyaM9WJ3Tmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uM0KMJmc4-SD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}